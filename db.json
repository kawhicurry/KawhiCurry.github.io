{"meta":{"version":1,"warehouse":"4.0.0"},"models":{"Asset":[{"_id":"themes/hexo-3/source/img/article-list-background.jpeg","path":"img/article-list-background.jpeg","modified":0,"renderable":1},{"_id":"themes/hexo-3/source/img/alipay.jpg","path":"img/alipay.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-3/source/img/brown-papersq.png","path":"img/brown-papersq.png","modified":0,"renderable":1},{"_id":"themes/hexo-3/source/img/gov.png","path":"img/gov.png","modified":0,"renderable":1},{"_id":"themes/hexo-3/source/img/school-book.png","path":"img/school-book.png","modified":0,"renderable":1},{"_id":"themes/hexo-3/source/img/weixin.jpg","path":"img/weixin.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-3/source/css/gitalk.css","path":"css/gitalk.css","modified":0,"renderable":1},{"_id":"themes/hexo-3/source/css/mobile.styl","path":"css/mobile.styl","modified":0,"renderable":1},{"_id":"themes/hexo-3/source/css/style.styl","path":"css/style.styl","modified":0,"renderable":1},{"_id":"themes/hexo-3/source/js/gitment.js","path":"js/gitment.js","modified":0,"renderable":1},{"_id":"themes/hexo-3/source/js/gitalk.js","path":"js/gitalk.js","modified":0,"renderable":1},{"_id":"themes/hexo-3/source/js/jquery.pjax.js","path":"js/jquery.pjax.js","modified":0,"renderable":1},{"_id":"themes/hexo-3/source/js/iconfont.js","path":"js/iconfont.js","modified":0,"renderable":1},{"_id":"themes/hexo-3/source/js/script.js","path":"js/script.js","modified":0,"renderable":1},{"_id":"themes/hexo-3/source/js/search.js","path":"js/search.js","modified":0,"renderable":1},{"_id":"themes/hexo-3/source/js/titleTip.js","path":"js/titleTip.js","modified":0,"renderable":1},{"_id":"themes/hexo-3/source/css/fonts/icomoon.svg","path":"css/fonts/icomoon.svg","modified":0,"renderable":1},{"_id":"themes/hexo-3/source/css/fonts/icomoon.eot","path":"css/fonts/icomoon.eot","modified":0,"renderable":1},{"_id":"themes/hexo-3/source/css/fonts/icomoon.woff","path":"css/fonts/icomoon.woff","modified":0,"renderable":1},{"_id":"themes/hexo-3/source/css/fonts/icomoon.ttf","path":"css/fonts/icomoon.ttf","modified":0,"renderable":1},{"_id":"themes/hexo-3/source/css/fonts/iconfont.eot","path":"css/fonts/iconfont.eot","modified":0,"renderable":1},{"_id":"themes/hexo-3/source/css/fonts/iconfont.svg","path":"css/fonts/iconfont.svg","modified":0,"renderable":1},{"_id":"themes/hexo-3/source/css/fonts/iconfont.ttf","path":"css/fonts/iconfont.ttf","modified":0,"renderable":1},{"_id":"themes/hexo-3/source/css/fonts/iconfont.woff","path":"css/fonts/iconfont.woff","modified":0,"renderable":1},{"_id":"themes/hexo-3/source/css/fonts/iconfont.woff2","path":"css/fonts/iconfont.woff2","modified":0,"renderable":1},{"_id":"themes/hexo-3/source/css/fonts/selection.json","path":"css/fonts/selection.json","modified":0,"renderable":1},{"_id":"themes/hexo-3/source/css/hl_theme/atom-light.styl","path":"css/hl_theme/atom-light.styl","modified":0,"renderable":1},{"_id":"themes/hexo-3/source/css/hl_theme/atom-dark.styl","path":"css/hl_theme/atom-dark.styl","modified":0,"renderable":1},{"_id":"themes/hexo-3/source/css/hl_theme/brown-paper.styl","path":"css/hl_theme/brown-paper.styl","modified":0,"renderable":1},{"_id":"themes/hexo-3/source/css/hl_theme/darcula.styl","path":"css/hl_theme/darcula.styl","modified":0,"renderable":1},{"_id":"themes/hexo-3/source/css/hl_theme/github-gist.styl","path":"css/hl_theme/github-gist.styl","modified":0,"renderable":1},{"_id":"themes/hexo-3/source/css/hl_theme/github.styl","path":"css/hl_theme/github.styl","modified":0,"renderable":1},{"_id":"themes/hexo-3/source/css/hl_theme/gruvbox-dark.styl","path":"css/hl_theme/gruvbox-dark.styl","modified":0,"renderable":1},{"_id":"themes/hexo-3/source/css/hl_theme/gruvbox-light.styl","path":"css/hl_theme/gruvbox-light.styl","modified":0,"renderable":1},{"_id":"themes/hexo-3/source/css/hl_theme/kimbie-dark.styl","path":"css/hl_theme/kimbie-dark.styl","modified":0,"renderable":1},{"_id":"themes/hexo-3/source/css/hl_theme/kimbie-light.styl","path":"css/hl_theme/kimbie-light.styl","modified":0,"renderable":1},{"_id":"themes/hexo-3/source/css/hl_theme/railscasts.styl","path":"css/hl_theme/railscasts.styl","modified":0,"renderable":1},{"_id":"themes/hexo-3/source/css/hl_theme/rainbow.styl","path":"css/hl_theme/rainbow.styl","modified":0,"renderable":1},{"_id":"themes/hexo-3/source/css/hl_theme/sublime.styl","path":"css/hl_theme/sublime.styl","modified":0,"renderable":1},{"_id":"themes/hexo-3/source/css/hl_theme/school-book.styl","path":"css/hl_theme/school-book.styl","modified":0,"renderable":1},{"_id":"themes/hexo-3/source/css/hl_theme/sunburst.styl","path":"css/hl_theme/sunburst.styl","modified":0,"renderable":1},{"_id":"themes/hexo-3/source/css/hl_theme/zenbum.styl","path":"css/hl_theme/zenbum.styl","modified":0,"renderable":1},{"_id":"themes/hexo-3/source/img/avatar.jpg","path":"img/avatar.jpg","modified":0,"renderable":1}],"Cache":[{"_id":"source/_posts/Daily-10-27.md","hash":"75cb01384c62a4758f32c009d4b53d45439006ef","modified":1635335425587},{"_id":"source/_posts/New-Start.md","hash":"ab9f6ae435bee0a8afaa6277d72154ade48d1d5c","modified":1635311491990},{"_id":"source/_posts/auto_fly.md","hash":"4a4ff4fe845080da38877049eeb9d0cfb1dac391","modified":1635311585876},{"_id":"source/_posts/hello-world.md","hash":"35d90c7899006361c0ef17642a2d69daa06fc7b6","modified":1635336855419},{"_id":"source/_posts/Qingyou-1.md","hash":"ac0e451439bf336b632bfbb970dfa6f7d170bc9f","modified":1635311580307},{"_id":"themes/hexo-3/README.md","hash":"19b8cfe6690c28427492f342e74dda5ed49a1664","modified":1635311491991},{"_id":"themes/hexo-3/LICENSE","hash":"b04140c5f682db2b300428f97bb164fd7f5f18bd","modified":1635311491991},{"_id":"themes/hexo-3/.gitignore","hash":"46eca80fe689a00cbe4d015c094702af54119021","modified":1635311491991},{"_id":"themes/hexo-3/_config.yml","hash":"aec9ba888d4bab18397b3ad914d7a85cd362c51e","modified":1635336904656},{"_id":"themes/hexo-3/languages/en.yml","hash":"616e02c035c86033ab4a97c5ae9e0a9e5f0b8ea3","modified":1635311491992},{"_id":"themes/hexo-3/languages/zh-CN.yml","hash":"83633d45420c96dfac41333aeac3f3616dca5286","modified":1635311491992},{"_id":"themes/hexo-3/layout/indexs.md","hash":"fefedd2be084fdd578be32aa886a6c7247835802","modified":1635338088687},{"_id":"themes/hexo-3/layout/index.ejs","hash":"1c185288c2925a652d577965626718e12df07f65","modified":1635311491999},{"_id":"themes/hexo-3/layout/post.ejs","hash":"a0eaba41e7ec9db5843af482470a45531049b457","modified":1635311491999},{"_id":"themes/hexo-3/layout/_partial/article.ejs","hash":"9e5afcc26f47f93c165072b0a2b5cbf72efb7ef9","modified":1635311491993},{"_id":"themes/hexo-3/layout/_partial/article_copyright.ejs","hash":"9e1cdec49d5b9b44399348d96ecd7331f3ee7d85","modified":1635311491993},{"_id":"themes/hexo-3/layout/_partial/comment.ejs","hash":"d18f94e04ef0cf7abb432a8e707ccb3abc7fe435","modified":1635311491993},{"_id":"themes/hexo-3/layout/_partial/copyright.ejs","hash":"4c09f47e899fe36bfe36d92b12996219c2b5f622","modified":1635311491996},{"_id":"themes/hexo-3/layout/_partial/dashang.ejs","hash":"b2a01cc1f0326965f0a186ce3c9b3c991fd4e2c9","modified":1635311491996},{"_id":"themes/hexo-3/layout/_partial/footer.ejs","hash":"9087af9647a87c3fa9ef87632de5427ba4abe9c4","modified":1635311491996},{"_id":"themes/hexo-3/layout/_partial/friends.ejs","hash":"e6dd90be668195016d6e1c51a6baefb50676e6ab","modified":1635311491996},{"_id":"themes/hexo-3/layout/_partial/full-toc.ejs","hash":"60a085fab3165ea1fc6370abac0bd6ab1b2f2510","modified":1635311491997},{"_id":"themes/hexo-3/layout/_partial/mathjax.ejs","hash":"e2be0e37f3d48e63e65a47d819bfb800b9aa3784","modified":1635311491997},{"_id":"themes/hexo-3/layout/_partial/header.ejs","hash":"1e04b617fe38acca8b3d3774c5dbfcb74a02db6b","modified":1635311491997},{"_id":"themes/hexo-3/layout/_partial/meta.ejs","hash":"ab6329ddd908b0567c18f39ac6a8553c6fec67c5","modified":1635311491997},{"_id":"themes/hexo-3/layout/_partial/nav-left.ejs","hash":"f3cc395fbb4e308776a38e369faefbc9e5891807","modified":1635311491998},{"_id":"themes/hexo-3/layout/_partial/nav-right.ejs","hash":"7942c661b48e15fced4a97acf86fac7fea013378","modified":1635311491998},{"_id":"themes/hexo-3/layout/_partial/toc-ref.ejs","hash":"33f7a4bfca1bb9835ec8f0d1e73188d1f56cc8b9","modified":1635311491998},{"_id":"themes/hexo-3/source/img/article-list-background.jpeg","hash":"4fdf8b3e53dd02d6ee6360aebfadb0cba1fb5633","modified":1635311492013},{"_id":"themes/hexo-3/layout/_partial/tag.ejs","hash":"8704e6bd833d270cc6a494d4e7cf1dfeddedba40","modified":1635311491998},{"_id":"themes/hexo-3/source/img/alipay.jpg","hash":"e457d1d3dfefbbd824d154cf756a2c6d10b812a2","modified":1635311492012},{"_id":"themes/hexo-3/source/img/brown-papersq.png","hash":"3a1332ede3a75a3d24f60b6ed69035b72da5e182","modified":1635311492014},{"_id":"themes/hexo-3/source/img/avatar.jpg","hash":"dae70e53f4eb5efd8f5bc8be7d5a8be9c49434e1","modified":1635338267981},{"_id":"themes/hexo-3/source/img/gov.png","hash":"f31c9f47faedf7f33b9580d6284ab891fb697560","modified":1635311492014},{"_id":"themes/hexo-3/source/img/school-book.png","hash":"711ec983c874e093bb89eb77afcbdf6741fa61ee","modified":1635311492015},{"_id":"themes/hexo-3/source/css/gitalk.css","hash":"3dc58e9a3fd63a3144d5fe850eb55e3dc885c9fb","modified":1635311492007},{"_id":"themes/hexo-3/source/css/mobile.styl","hash":"1c2f8b7d7cf46f219adb3a628bdf380f29ff4a6b","modified":1635311492011},{"_id":"themes/hexo-3/source/css/style.styl","hash":"29fa7f6619519c2dcfec4efac4314c5af659a92a","modified":1635311492012},{"_id":"themes/hexo-3/source/js/jquery.pjax.js","hash":"8c2a4f10a4da3d9615a3a81542494c6d21479b3d","modified":1635311492022},{"_id":"themes/hexo-3/source/js/iconfont.js","hash":"3a0869ca1b09af07d82987e343a3bc4cb9558ecb","modified":1635311492021},{"_id":"themes/hexo-3/source/js/script.js","hash":"36275888d57fecb6afd2c6f9291c46c2b3894ac5","modified":1635311492022},{"_id":"themes/hexo-3/source/js/search.js","hash":"788c610149a5f9361295f9f0207c8523f37ddb8b","modified":1635311492022},{"_id":"themes/hexo-3/source/js/titleTip.js","hash":"7299ac046ddd6e6a4267d435f7b4c8198baaaccc","modified":1635311492023},{"_id":"themes/hexo-3/layout/_partial/comments/disqus.ejs","hash":"32ce7b48d366b9c888ff2ceb911a3cd82f864537","modified":1635311491994},{"_id":"themes/hexo-3/layout/_partial/comments/gitment.ejs","hash":"eaf2b6f297282606b630ad55fb9e38af7e2829dc","modified":1635311491995},{"_id":"themes/hexo-3/layout/_partial/comments/click2show.ejs","hash":"05b09c45b379ffeb4f48c1604044d88829f90799","modified":1635311491994},{"_id":"themes/hexo-3/layout/_partial/comments/gitalk.ejs","hash":"01567e010cf4f2dd141fe2019490d3f0d5aa2529","modified":1635311491994},{"_id":"themes/hexo-3/layout/_partial/comments/livere.ejs","hash":"2d115e79cadedc2d5d8f4b5618559640d986e01f","modified":1635311491995},{"_id":"themes/hexo-3/layout/_partial/comments/utteranc.ejs","hash":"8f2d4f42fbad351677c82e72420224587a5bd666","modified":1635311491995},{"_id":"themes/hexo-3/source/css/fonts/icomoon.svg","hash":"b5e7562c8494b0ddb3a70ecc5545ef7340d8e971","modified":1635311492003},{"_id":"themes/hexo-3/source/css/fonts/icomoon.eot","hash":"b6195bedc1cb2f9cfcb26cc27021f2e94be2ab0a","modified":1635311492003},{"_id":"themes/hexo-3/source/css/fonts/icomoon.woff","hash":"3985d29416bb9b19f50a2f20f2bbbce47f10af8d","modified":1635311492004},{"_id":"themes/hexo-3/source/css/fonts/icomoon.ttf","hash":"eb976d8b8559fcddfc2658a03a4350cb566fc06b","modified":1635311492003},{"_id":"themes/hexo-3/source/css/fonts/iconfont.eot","hash":"b14b8624988ff069aff3145f88c0d7ac49052bd3","modified":1635311492004},{"_id":"themes/hexo-3/source/css/fonts/iconfont.svg","hash":"3630aabf2f9c0417f483ebd03d9e429dbc2594e0","modified":1635311492005},{"_id":"themes/hexo-3/source/css/fonts/iconfont.ttf","hash":"140829ecf12d30c6e18d8dc6dc0c188a66addd25","modified":1635311492005},{"_id":"themes/hexo-3/source/css/fonts/iconfont.woff","hash":"0d2d4559f1ac4fa801eb8cc099fa5bf9dcf955ef","modified":1635311492006},{"_id":"themes/hexo-3/source/css/fonts/iconfont.woff2","hash":"b0317a0b2ebb1181a8bf5a97d03556dd54538645","modified":1635311492006},{"_id":"themes/hexo-3/source/css/fonts/selection.json","hash":"b6456a4eabcffd95e822d1d7adce96da524d481a","modified":1635311492006},{"_id":"themes/hexo-3/source/css/_partial/dashang.styl","hash":"f0eac1dc1f5dbed1769d032bb5fd5f002faaee26","modified":1635311492000},{"_id":"themes/hexo-3/source/css/_partial/comment.styl","hash":"d5fa333970a2eac66937d42eeb16fdb362e121ed","modified":1635311492000},{"_id":"themes/hexo-3/source/css/_partial/fade.styl","hash":"02c7510a26f306e240f23ddbf772a69be2c890dd","modified":1635311492000},{"_id":"themes/hexo-3/source/css/_partial/font.styl","hash":"3db01e603985e6dbcacb6b0f13dbd804f5849e3c","modified":1635311492001},{"_id":"themes/hexo-3/source/css/_partial/full-toc.styl","hash":"9a732af065d0a80c9e420934be0f3582bf0129dc","modified":1635311492001},{"_id":"themes/hexo-3/source/css/_partial/nav-left.styl","hash":"0a067ced25025000aa33c8f5017c87fff0971378","modified":1635311492001},{"_id":"themes/hexo-3/source/css/_partial/nav-right.styl","hash":"588b75e3b83ed95e526154bf3c0336c6f33e2be7","modified":1635311492001},{"_id":"themes/hexo-3/source/css/_partial/nprogress.styl","hash":"2620a02169a6aeb75137fd368eac2c36423d8498","modified":1635311492002},{"_id":"themes/hexo-3/source/css/_partial/num-load.styl","hash":"f7ef35459ece22e1da950b86126be1c2bfe97fcf","modified":1635311492002},{"_id":"themes/hexo-3/source/css/_partial/post.styl","hash":"f1251e2a3b5334af3a22b51fc0293c2456568b50","modified":1635311492002},{"_id":"themes/hexo-3/source/css/hl_theme/atom-light.styl","hash":"553987211d3323a7dfc0b08786b183a3435978c9","modified":1635311492007},{"_id":"themes/hexo-3/source/css/hl_theme/atom-dark.styl","hash":"f3eb4e5feda9cbd6242ccf44ca064e2979b5d719","modified":1635311492007},{"_id":"themes/hexo-3/source/css/hl_theme/brown-paper.styl","hash":"03af387edcc1cf8c18d12e9c440fd51b6cf425b6","modified":1635311492008},{"_id":"themes/hexo-3/source/css/hl_theme/darcula.styl","hash":"2bfc14f27ccca108b4b3755782de8366e8bd001e","modified":1635311492008},{"_id":"themes/hexo-3/source/css/hl_theme/github-gist.styl","hash":"5e05b19832c1099bd9d284bc3ed00dc8a3d7ee23","modified":1635311492008},{"_id":"themes/hexo-3/source/css/hl_theme/github.styl","hash":"53276ff1f224f691dfe811e82c0af7f4476abf5d","modified":1635311492008},{"_id":"themes/hexo-3/source/css/hl_theme/gruvbox-dark.styl","hash":"315ad610d303caba9eac80a7d51002193a15478a","modified":1635311492009},{"_id":"themes/hexo-3/source/css/hl_theme/gruvbox-light.styl","hash":"1bece084b1dbbbd4af064f05feffd8c332b96a48","modified":1635311492009},{"_id":"themes/hexo-3/source/css/hl_theme/kimbie-dark.styl","hash":"e9c190f9ffc37a13cac430512e4e0c760205be4a","modified":1635311492009},{"_id":"themes/hexo-3/source/css/hl_theme/kimbie-light.styl","hash":"0c3ccd0d64e7504c7061d246dc32737f502f64e4","modified":1635311492009},{"_id":"themes/hexo-3/source/css/hl_theme/railscasts.styl","hash":"a6e8cfd2202afd7893f5268f3437421e35066e7b","modified":1635311492010},{"_id":"themes/hexo-3/source/css/hl_theme/rainbow.styl","hash":"e5c37646a9d9c1094f9aab7a7c65a4b242e8db00","modified":1635311492010},{"_id":"themes/hexo-3/source/css/hl_theme/sublime.styl","hash":"501d75ef0f4385bea24d9b9b4cc434ba68d4be27","modified":1635311492010},{"_id":"themes/hexo-3/source/css/hl_theme/school-book.styl","hash":"51659351b391a2be5c68728bb51b7ad467c5e0db","modified":1635311492010},{"_id":"themes/hexo-3/source/css/hl_theme/sunburst.styl","hash":"2aa9817e68fb2ed216781ea04b733039ebe18214","modified":1635311492011},{"_id":"themes/hexo-3/source/css/hl_theme/zenbum.styl","hash":"92941a6ae73b74f44ad7c559c5548c44073c644a","modified":1635311492011},{"_id":"themes/hexo-3/source/img/weixin.jpg","hash":"8dafb22561698d0758fba9ea2a45abf6ad3512a2","modified":1635311492016},{"_id":"themes/hexo-3/source/js/gitment.js","hash":"67984b83cd46ff4300d4fd959bf6c17dd66b4136","modified":1635311492021},{"_id":"themes/hexo-3/source/js/gitalk.js","hash":"3e2e0cf9caa6b8d07b9c5e0733a1ccb3e244259f","modified":1635311492019},{"_id":"public/2021/10/27/auto_fly/index.html","hash":"1c0aa3ab01691a8f0b0a1f3669abbee8cc9c1593","modified":1635336437569},{"_id":"public/2021/10/25/New-Start/index.html","hash":"9e283d2b4715c627d4199fe84299f6b7153447d3","modified":1636816880156},{"_id":"public/categories/life/index.html","hash":"9ceba1a2cc58976cb4184ff8c8dd469ffe35d27f","modified":1636816880156},{"_id":"public/archives/index.html","hash":"9ceba1a2cc58976cb4184ff8c8dd469ffe35d27f","modified":1636816880156},{"_id":"public/archives/2021/index.html","hash":"9ceba1a2cc58976cb4184ff8c8dd469ffe35d27f","modified":1636816880156},{"_id":"public/archives/2021/10/index.html","hash":"9ceba1a2cc58976cb4184ff8c8dd469ffe35d27f","modified":1636816880156},{"_id":"public/index.html","hash":"9ceba1a2cc58976cb4184ff8c8dd469ffe35d27f","modified":1636816880156},{"_id":"public/2021/10/27/Daily-10-27/index.html","hash":"ad3dacd348f0090cb0bd0040413a2587d2689311","modified":1636816880156},{"_id":"public/2021/10/27/hello-world/index.html","hash":"7e6b96d000204a8c48baae1c791739b6e45764ac","modified":1635336437569},{"_id":"public/2021/10/27/Qingyou-1/index.html","hash":"c446f59b2691b1edc693372121618632b27f36f8","modified":1636816880156},{"_id":"public/tags/Daily/index.html","hash":"9ceba1a2cc58976cb4184ff8c8dd469ffe35d27f","modified":1636816880156},{"_id":"public/img/article-list-background.jpeg","hash":"4fdf8b3e53dd02d6ee6360aebfadb0cba1fb5633","modified":1635336437569},{"_id":"public/img/alipay.jpg","hash":"e457d1d3dfefbbd824d154cf756a2c6d10b812a2","modified":1635336437569},{"_id":"public/img/avatar.jpg","hash":"dae70e53f4eb5efd8f5bc8be7d5a8be9c49434e1","modified":1635338285438},{"_id":"public/img/brown-papersq.png","hash":"3a1332ede3a75a3d24f60b6ed69035b72da5e182","modified":1635336437569},{"_id":"public/img/gov.png","hash":"f31c9f47faedf7f33b9580d6284ab891fb697560","modified":1635336437569},{"_id":"public/img/school-book.png","hash":"711ec983c874e093bb89eb77afcbdf6741fa61ee","modified":1635336437569},{"_id":"public/css/fonts/icomoon.svg","hash":"b5e7562c8494b0ddb3a70ecc5545ef7340d8e971","modified":1635336437569},{"_id":"public/css/fonts/icomoon.woff","hash":"3985d29416bb9b19f50a2f20f2bbbce47f10af8d","modified":1635336437569},{"_id":"public/css/fonts/icomoon.eot","hash":"b6195bedc1cb2f9cfcb26cc27021f2e94be2ab0a","modified":1635336437569},{"_id":"public/css/fonts/icomoon.ttf","hash":"eb976d8b8559fcddfc2658a03a4350cb566fc06b","modified":1635336437569},{"_id":"public/css/fonts/iconfont.eot","hash":"b14b8624988ff069aff3145f88c0d7ac49052bd3","modified":1635336437569},{"_id":"public/css/fonts/iconfont.svg","hash":"3630aabf2f9c0417f483ebd03d9e429dbc2594e0","modified":1635336437569},{"_id":"public/css/fonts/iconfont.ttf","hash":"140829ecf12d30c6e18d8dc6dc0c188a66addd25","modified":1635336437569},{"_id":"public/css/fonts/iconfont.woff","hash":"0d2d4559f1ac4fa801eb8cc099fa5bf9dcf955ef","modified":1635336437569},{"_id":"public/css/fonts/iconfont.woff2","hash":"b0317a0b2ebb1181a8bf5a97d03556dd54538645","modified":1635336437569},{"_id":"public/img/weixin.jpg","hash":"8dafb22561698d0758fba9ea2a45abf6ad3512a2","modified":1635336437569},{"_id":"public/css/mobile.css","hash":"5998f6fc27998596beb1e40e4bc3c43be2ed764c","modified":1635336437569},{"_id":"public/js/search.js","hash":"c80c9a231ee040c7adc07a477793873fb85ce8bc","modified":1635336437569},{"_id":"public/js/titleTip.js","hash":"81dca549063e29ba3a4a278f0f4388eba8a2167b","modified":1635336437569},{"_id":"public/css/hl_theme/atom-light.css","hash":"d31edb9816dae6b01410028bceb91757a962f780","modified":1635336437569},{"_id":"public/css/hl_theme/brown-paper.css","hash":"500c8e750373f6656ff49a7857c871ceedcf8777","modified":1635336437569},{"_id":"public/css/hl_theme/atom-dark.css","hash":"88d11052a24e8100af6248eb4dbe1ce7b0e96408","modified":1635336437569},{"_id":"public/css/hl_theme/github-gist.css","hash":"7a41c1c479d09df875f99f1f6d94aac42e9e2ad0","modified":1635336437569},{"_id":"public/css/hl_theme/darcula.css","hash":"4341074bae4bc9f0b86e32b623e27babc0159b6e","modified":1635336437569},{"_id":"public/css/hl_theme/github.css","hash":"e05a0806a508a26b9f3f3794b6b588ec6504ad3f","modified":1635336437569},{"_id":"public/css/hl_theme/kimbie-dark.css","hash":"728527fcc308da454722c119b89e6da3025bd1e3","modified":1635336437569},{"_id":"public/css/hl_theme/kimbie-light.css","hash":"0c61926c989163faefb031d27bce3e287d6e10f2","modified":1635336437569},{"_id":"public/css/hl_theme/gruvbox-dark.css","hash":"8c440d9b4ee19ac03eaee3c6af78ba52e5ba5535","modified":1635336437569},{"_id":"public/css/hl_theme/gruvbox-light.css","hash":"30514aaa242a34647aa666cfca4fc74c595ea8f2","modified":1635336437569},{"_id":"public/css/hl_theme/railscasts.css","hash":"511f2fd2a84d426e5da5cb17880cc08f73beb002","modified":1635336437569},{"_id":"public/css/hl_theme/rainbow.css","hash":"7ff4251938076ddb7e4e49413db82653e5b61321","modified":1635336437569},{"_id":"public/css/hl_theme/sublime.css","hash":"f65c5b116d9213afb9c324384a2f3bc86cb71121","modified":1635336437569},{"_id":"public/css/hl_theme/sunburst.css","hash":"8a135abac1512cf430d1d1ad2304b79afa1a4d6e","modified":1635336437569},{"_id":"public/css/hl_theme/school-book.css","hash":"ffbbcd13a74ac2404262c50b7a43053dfd0096ff","modified":1635336437569},{"_id":"public/css/hl_theme/zenbum.css","hash":"0a78f74a93568e20b32ca7427c719e9bae9a0b55","modified":1635336437569},{"_id":"public/css/style.css","hash":"db3b1cc156de2bd7563399cf74eeabf9abde50a7","modified":1635336437569},{"_id":"public/css/gitalk.css","hash":"58177ce227c50ee359fbf99a4fdd26058887afc5","modified":1635336437569},{"_id":"public/js/jquery.pjax.js","hash":"191c49fdb40dff115a49cfd2b30dffb888d86550","modified":1635336437569},{"_id":"public/css/fonts/selection.json","hash":"047b615ea32dc48dae5b964061427d41feaaafdf","modified":1635336437569},{"_id":"public/js/script.js","hash":"d7efd27ade371c6e50d0d7481ffc0ec47018bad2","modified":1635336437569},{"_id":"public/js/iconfont.js","hash":"3a0869ca1b09af07d82987e343a3bc4cb9558ecb","modified":1635336437569},{"_id":"public/js/gitment.js","hash":"59a1e03f2b0ce61dd9bd405d3c52d3e07cc10dec","modified":1635336437569},{"_id":"public/js/gitalk.js","hash":"26ba4841dcb4b178f730f53a8d1f4a7c89442b4f","modified":1635336437569},{"_id":"public/2021/10/25/hello-world/index.html","hash":"61429da11f5a78768f6db7276c92e8d2f881fbe4","modified":1636816880156},{"_id":"themes/hexo-3/source/img/avatar.jpeg","hash":"dae70e53f4eb5efd8f5bc8be7d5a8be9c49434e1","modified":1635337221362},{"_id":"public/img/avatar.jpeg","hash":"dae70e53f4eb5efd8f5bc8be7d5a8be9c49434e1","modified":1635338099687},{"_id":"source/_posts/Magic-Macro.md","hash":"8e5507170c3d9d429faa0ba328332931e764e4b0","modified":1636290868751},{"_id":"public/archives/2021/11/index.html","hash":"9ceba1a2cc58976cb4184ff8c8dd469ffe35d27f","modified":1636816880156},{"_id":"public/categories/Language/index.html","hash":"9ceba1a2cc58976cb4184ff8c8dd469ffe35d27f","modified":1636816880156},{"_id":"public/tags/C/index.html","hash":"9ceba1a2cc58976cb4184ff8c8dd469ffe35d27f","modified":1636816880156},{"_id":"public/2021/11/07/Magic-Macro/index.html","hash":"ee5912400766ac07519454b5174468d9708159ea","modified":1636816880156},{"_id":"public/categories/Language/C/index.html","hash":"7812607275034d0bb90a6eeb3911022e05fe44c3","modified":1636290850429},{"_id":"source/_posts/log-a-git-error.md","hash":"34dd9bd705c9139997ca37ffbf2aeef094a11d93","modified":1636546305333},{"_id":"public/2021/11/10/log-a-git-error/index.html","hash":"e29bc2c13d0bfc0860e959ae6b3d7672cc107acb","modified":1636816880156},{"_id":"public/categories/tool/index.html","hash":"9ceba1a2cc58976cb4184ff8c8dd469ffe35d27f","modified":1636816880156},{"_id":"public/tags/git/index.html","hash":"9ceba1a2cc58976cb4184ff8c8dd469ffe35d27f","modified":1636816880156},{"_id":"source/_posts/123.md","hash":"670731322947b00f61ee1a5ccbf464f920a0efd0","modified":1636815789358},{"_id":"source/_posts/net-server-0.md","hash":"676cd345e046f0dfbc162f4a1120fc216745bbf4","modified":1636816875570},{"_id":"source/_posts/qyauto.md","hash":"3cf9969d118568c53c4143536829259599c241b3","modified":1636812599091},{"_id":"public/2021/11/13/net-server-0/index.html","hash":"077306256fd0ac29d99fa8fdb48e1f521486e908","modified":1636816880156},{"_id":"public/2021/11/13/123/index.html","hash":"b2088a004a0b16a7310592568a7db447483e2078","modified":1636816880156},{"_id":"public/tags/cloud/index.html","hash":"9ceba1a2cc58976cb4184ff8c8dd469ffe35d27f","modified":1636816880156},{"_id":"public/categories/uncategorized/index.html","hash":"9ceba1a2cc58976cb4184ff8c8dd469ffe35d27f","modified":1636816880156},{"_id":"source/_scraft/qyauto.md","hash":"3cf9969d118568c53c4143536829259599c241b3","modified":1636816916914}],"Category":[{"name":"life","_id":"ckv9h3bhm0007e0ul1maa6qdr"},{"name":"Language","_id":"ckvp97s130001a4ulg84g3g0u"},{"name":"C","parent":"ckvp97s130001a4ulg84g3g0u","_id":"ckvp9bp0x0000youl6z5yd2nk"},{"name":"tool","_id":"ckvthffer0001bkulfdvge9xx"},{"name":"uncategorized","_id":"ckvxyic7a0002e0ulf852d98u"}],"Data":[],"Page":[],"Post":[{"title":"Daily-10-27","date":"2021-10-27T10:57:04.000Z","_content":"\n# Daily-10-27\n\n谁都想不到第一次挑战会来的这么快，前两天还在悠哉游哉的看镜像站，今天就遇到了空前绝后大危机。学校的服务器似乎遇上了arp广播风暴，信息办和青柚几乎所有的服务都down了。两位后端学长带着我去了信息办，用了一下午来试着恢复所有service，顺便还参观了一下信息办的机房。\n\n今天早上才写了{% post_link Qingyou-1 %}这篇文章，说到同时加班我摸鱼。这个摸鱼确实没得办法，毕竟是业务处理方面的事情，但今天这个服务器down了，可就是彻彻底底要运维干活了（然后我还是在摸鱼）。早上本来在开开心心的在github上搭自己的blog，本来很开心的发现hexo的源代码和deploy用的现成文件可以直接用`git branch`分开来。结果到了中午，突然说学校的内部网络出了超级大问题，连食堂都刷不上卡。中午两位后端学长都到了，然后带着我去了信息办，坐在某个开会的桌子边重启服务。主要是两位学长在做，我最多起一个记录的作用。下面是一些印象深刻的记录。\n\n1. 最主要的两台服务器，理论是完全一样的，但一台可以正常运行，另一台卡死，reboot都卡死。并且tomcat父进程为1，无法kill，同时其log文件夹无法打开，无法ls、du，free显示内存占满，swap分区16g全满。最后只能物理重启，重启后可以正常使用了，从另一台服务器上copy过来了配置。\n2. 搭载某部门服务的服务器，80+443端口都无法使用，但ssh连接正常，redis没有设置登录密码，但是手动登录时要求密码了，reboot之后可以正常使用了，但是证书似乎还有问题，两个学长也没解决。\n3. 搭载另一部门服务的服务器，服务down了，重启服务后可正常使用。\n\n除此之外还有各种容器需要重启，有的是学长搭建的，如果不及时记录的话，还真不一定记得住他们的作用。\n\n本来下午约了去飞无人机，果断推到明天了，不过无人机的代码倒是早就写好了。本以为明天没课的，约时间调试无人机的时候才想起来明天还有个实验课。又是不想上课的一天。\n\n不管怎么说，今天下午还是多多少少学到了点nouns，也深刻意识到一个了解服务的运维的重要性，此前的服务都是后端同学手动搭的，幸好他们还记得相关信息，不然我现在的能力可做不到完美恢复。除此之外，我对网络、数据库的了解还是差的太多。\n\n对于未来的话，希望能早点上云吧，服务也希望能够系统化一点，文档可以多写一点。\n\n以上。\n\n","source":"_posts/Daily-10-27.md","raw":"---\ntitle: Daily-10-27\ndate: 2021-10-27 18:57:04\ntags: Daily\n---\n\n# Daily-10-27\n\n谁都想不到第一次挑战会来的这么快，前两天还在悠哉游哉的看镜像站，今天就遇到了空前绝后大危机。学校的服务器似乎遇上了arp广播风暴，信息办和青柚几乎所有的服务都down了。两位后端学长带着我去了信息办，用了一下午来试着恢复所有service，顺便还参观了一下信息办的机房。\n\n今天早上才写了{% post_link Qingyou-1 %}这篇文章，说到同时加班我摸鱼。这个摸鱼确实没得办法，毕竟是业务处理方面的事情，但今天这个服务器down了，可就是彻彻底底要运维干活了（然后我还是在摸鱼）。早上本来在开开心心的在github上搭自己的blog，本来很开心的发现hexo的源代码和deploy用的现成文件可以直接用`git branch`分开来。结果到了中午，突然说学校的内部网络出了超级大问题，连食堂都刷不上卡。中午两位后端学长都到了，然后带着我去了信息办，坐在某个开会的桌子边重启服务。主要是两位学长在做，我最多起一个记录的作用。下面是一些印象深刻的记录。\n\n1. 最主要的两台服务器，理论是完全一样的，但一台可以正常运行，另一台卡死，reboot都卡死。并且tomcat父进程为1，无法kill，同时其log文件夹无法打开，无法ls、du，free显示内存占满，swap分区16g全满。最后只能物理重启，重启后可以正常使用了，从另一台服务器上copy过来了配置。\n2. 搭载某部门服务的服务器，80+443端口都无法使用，但ssh连接正常，redis没有设置登录密码，但是手动登录时要求密码了，reboot之后可以正常使用了，但是证书似乎还有问题，两个学长也没解决。\n3. 搭载另一部门服务的服务器，服务down了，重启服务后可正常使用。\n\n除此之外还有各种容器需要重启，有的是学长搭建的，如果不及时记录的话，还真不一定记得住他们的作用。\n\n本来下午约了去飞无人机，果断推到明天了，不过无人机的代码倒是早就写好了。本以为明天没课的，约时间调试无人机的时候才想起来明天还有个实验课。又是不想上课的一天。\n\n不管怎么说，今天下午还是多多少少学到了点nouns，也深刻意识到一个了解服务的运维的重要性，此前的服务都是后端同学手动搭的，幸好他们还记得相关信息，不然我现在的能力可做不到完美恢复。除此之外，我对网络、数据库的了解还是差的太多。\n\n对于未来的话，希望能早点上云吧，服务也希望能够系统化一点，文档可以多写一点。\n\n以上。\n\n","slug":"Daily-10-27","published":1,"updated":"2021-10-27T11:50:25.587Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckv9h3bh40000e0ula1dfa3j2","content":"<h1 id=\"Daily-10-27\"><a href=\"#Daily-10-27\" class=\"headerlink\" title=\"Daily-10-27\"></a>Daily-10-27</h1><p>谁都想不到第一次挑战会来的这么快，前两天还在悠哉游哉的看镜像站，今天就遇到了空前绝后大危机。学校的服务器似乎遇上了arp广播风暴，信息办和青柚几乎所有的服务都down了。两位后端学长带着我去了信息办，用了一下午来试着恢复所有service，顺便还参观了一下信息办的机房。</p>\n<p>今天早上才写了<a href=\"/2021/10/27/Qingyou-1/\" title=\"Qingyou_1\">Qingyou_1</a>这篇文章，说到同时加班我摸鱼。这个摸鱼确实没得办法，毕竟是业务处理方面的事情，但今天这个服务器down了，可就是彻彻底底要运维干活了（然后我还是在摸鱼）。早上本来在开开心心的在github上搭自己的blog，本来很开心的发现hexo的源代码和deploy用的现成文件可以直接用<code>git branch</code>分开来。结果到了中午，突然说学校的内部网络出了超级大问题，连食堂都刷不上卡。中午两位后端学长都到了，然后带着我去了信息办，坐在某个开会的桌子边重启服务。主要是两位学长在做，我最多起一个记录的作用。下面是一些印象深刻的记录。</p>\n<ol>\n<li>最主要的两台服务器，理论是完全一样的，但一台可以正常运行，另一台卡死，reboot都卡死。并且tomcat父进程为1，无法kill，同时其log文件夹无法打开，无法ls、du，free显示内存占满，swap分区16g全满。最后只能物理重启，重启后可以正常使用了，从另一台服务器上copy过来了配置。</li>\n<li>搭载某部门服务的服务器，80+443端口都无法使用，但ssh连接正常，redis没有设置登录密码，但是手动登录时要求密码了，reboot之后可以正常使用了，但是证书似乎还有问题，两个学长也没解决。</li>\n<li>搭载另一部门服务的服务器，服务down了，重启服务后可正常使用。</li>\n</ol>\n<p>除此之外还有各种容器需要重启，有的是学长搭建的，如果不及时记录的话，还真不一定记得住他们的作用。</p>\n<p>本来下午约了去飞无人机，果断推到明天了，不过无人机的代码倒是早就写好了。本以为明天没课的，约时间调试无人机的时候才想起来明天还有个实验课。又是不想上课的一天。</p>\n<p>不管怎么说，今天下午还是多多少少学到了点nouns，也深刻意识到一个了解服务的运维的重要性，此前的服务都是后端同学手动搭的，幸好他们还记得相关信息，不然我现在的能力可做不到完美恢复。除此之外，我对网络、数据库的了解还是差的太多。</p>\n<p>对于未来的话，希望能早点上云吧，服务也希望能够系统化一点，文档可以多写一点。</p>\n<p>以上。</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"Daily-10-27\"><a href=\"#Daily-10-27\" class=\"headerlink\" title=\"Daily-10-27\"></a>Daily-10-27</h1><p>谁都想不到第一次挑战会来的这么快，前两天还在悠哉游哉的看镜像站，今天就遇到了空前绝后大危机。学校的服务器似乎遇上了arp广播风暴，信息办和青柚几乎所有的服务都down了。两位后端学长带着我去了信息办，用了一下午来试着恢复所有service，顺便还参观了一下信息办的机房。</p>\n<p>今天早上才写了<a href=\"/2021/10/27/Qingyou-1/\" title=\"Qingyou_1\">Qingyou_1</a>这篇文章，说到同时加班我摸鱼。这个摸鱼确实没得办法，毕竟是业务处理方面的事情，但今天这个服务器down了，可就是彻彻底底要运维干活了（然后我还是在摸鱼）。早上本来在开开心心的在github上搭自己的blog，本来很开心的发现hexo的源代码和deploy用的现成文件可以直接用<code>git branch</code>分开来。结果到了中午，突然说学校的内部网络出了超级大问题，连食堂都刷不上卡。中午两位后端学长都到了，然后带着我去了信息办，坐在某个开会的桌子边重启服务。主要是两位学长在做，我最多起一个记录的作用。下面是一些印象深刻的记录。</p>\n<ol>\n<li>最主要的两台服务器，理论是完全一样的，但一台可以正常运行，另一台卡死，reboot都卡死。并且tomcat父进程为1，无法kill，同时其log文件夹无法打开，无法ls、du，free显示内存占满，swap分区16g全满。最后只能物理重启，重启后可以正常使用了，从另一台服务器上copy过来了配置。</li>\n<li>搭载某部门服务的服务器，80+443端口都无法使用，但ssh连接正常，redis没有设置登录密码，但是手动登录时要求密码了，reboot之后可以正常使用了，但是证书似乎还有问题，两个学长也没解决。</li>\n<li>搭载另一部门服务的服务器，服务down了，重启服务后可正常使用。</li>\n</ol>\n<p>除此之外还有各种容器需要重启，有的是学长搭建的，如果不及时记录的话，还真不一定记得住他们的作用。</p>\n<p>本来下午约了去飞无人机，果断推到明天了，不过无人机的代码倒是早就写好了。本以为明天没课的，约时间调试无人机的时候才想起来明天还有个实验课。又是不想上课的一天。</p>\n<p>不管怎么说，今天下午还是多多少少学到了点nouns，也深刻意识到一个了解服务的运维的重要性，此前的服务都是后端同学手动搭的，幸好他们还记得相关信息，不然我现在的能力可做不到完美恢复。除此之外，我对网络、数据库的了解还是差的太多。</p>\n<p>对于未来的话，希望能早点上云吧，服务也希望能够系统化一点，文档可以多写一点。</p>\n<p>以上。</p>\n"},{"title":"Hello World","date":"2021-10-25T01:01:06.000Z","_content":"Welcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/one-command-deployment.html)\n","source":"_posts/hello-world.md","raw":"---\ntitle: Hello World\ndate: 2021-10-25 09:01:06\ncategories:\ntags:\n---\nWelcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/one-command-deployment.html)\n","slug":"hello-world","published":1,"updated":"2021-10-27T12:14:15.419Z","_id":"ckv9h3bha0001e0ul5i8w8x67","comments":1,"layout":"post","photos":[],"link":"","content":"<p>Welcome to <a href=\"https://hexo.io/\">Hexo</a>! This is your very first post. Check <a href=\"https://hexo.io/docs/\">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href=\"https://hexo.io/docs/troubleshooting.html\">troubleshooting</a> or you can ask me on <a href=\"https://github.com/hexojs/hexo/issues\">GitHub</a>.</p>\n<h2 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h2><h3 id=\"Create-a-new-post\"><a href=\"#Create-a-new-post\" class=\"headerlink\" title=\"Create a new post\"></a>Create a new post</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo new <span class=\"string\">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/writing.html\">Writing</a></p>\n<h3 id=\"Run-server\"><a href=\"#Run-server\" class=\"headerlink\" title=\"Run server\"></a>Run server</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo server</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/server.html\">Server</a></p>\n<h3 id=\"Generate-static-files\"><a href=\"#Generate-static-files\" class=\"headerlink\" title=\"Generate static files\"></a>Generate static files</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo generate</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/generating.html\">Generating</a></p>\n<h3 id=\"Deploy-to-remote-sites\"><a href=\"#Deploy-to-remote-sites\" class=\"headerlink\" title=\"Deploy to remote sites\"></a>Deploy to remote sites</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo deploy</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/one-command-deployment.html\">Deployment</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p>Welcome to <a href=\"https://hexo.io/\">Hexo</a>! This is your very first post. Check <a href=\"https://hexo.io/docs/\">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href=\"https://hexo.io/docs/troubleshooting.html\">troubleshooting</a> or you can ask me on <a href=\"https://github.com/hexojs/hexo/issues\">GitHub</a>.</p>\n<h2 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h2><h3 id=\"Create-a-new-post\"><a href=\"#Create-a-new-post\" class=\"headerlink\" title=\"Create a new post\"></a>Create a new post</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo new <span class=\"string\">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/writing.html\">Writing</a></p>\n<h3 id=\"Run-server\"><a href=\"#Run-server\" class=\"headerlink\" title=\"Run server\"></a>Run server</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo server</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/server.html\">Server</a></p>\n<h3 id=\"Generate-static-files\"><a href=\"#Generate-static-files\" class=\"headerlink\" title=\"Generate static files\"></a>Generate static files</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo generate</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/generating.html\">Generating</a></p>\n<h3 id=\"Deploy-to-remote-sites\"><a href=\"#Deploy-to-remote-sites\" class=\"headerlink\" title=\"Deploy to remote sites\"></a>Deploy to remote sites</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo deploy</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/one-command-deployment.html\">Deployment</a></p>\n"},{"title":"New-Start","date":"2021-10-25T09:45:59.000Z","_content":"\n# New Start\n\nToday I start a new blog with domain: [kawhicurry.shuihua.top](kawhicurry.shuihua.top).\n\nI hope I can keep the anything I meet after now.\n\nRecord the things that refresh, happy, knowledgeable or miserable, sad, terrible.","source":"_posts/New-Start.md","raw":"---\ntitle: New-Start\ndate: 2021-10-25 17:45:59\ntags:\n---\n\n# New Start\n\nToday I start a new blog with domain: [kawhicurry.shuihua.top](kawhicurry.shuihua.top).\n\nI hope I can keep the anything I meet after now.\n\nRecord the things that refresh, happy, knowledgeable or miserable, sad, terrible.","slug":"New-Start","published":1,"updated":"2021-10-27T05:11:31.990Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckv9h3bhi0003e0ul3w9d9330","content":"<h1 id=\"New-Start\"><a href=\"#New-Start\" class=\"headerlink\" title=\"New Start\"></a>New Start</h1><p>Today I start a new blog with domain: <a href=\"kawhicurry.shuihua.top\">kawhicurry.shuihua.top</a>.</p>\n<p>I hope I can keep the anything I meet after now.</p>\n<p>Record the things that refresh, happy, knowledgeable or miserable, sad, terrible.</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"New-Start\"><a href=\"#New-Start\" class=\"headerlink\" title=\"New Start\"></a>New Start</h1><p>Today I start a new blog with domain: <a href=\"kawhicurry.shuihua.top\">kawhicurry.shuihua.top</a>.</p>\n<p>I hope I can keep the anything I meet after now.</p>\n<p>Record the things that refresh, happy, knowledgeable or miserable, sad, terrible.</p>\n"},{"title":"Qingyou_1","date":"2021-10-27T01:01:06.000Z","_content":"# 青柚的这点事（1）\n\n大一开学的时候被学校拉去听优秀学生讲座。然后青柚的指导老师上去宣传了一波，我就记得两件事：\n\n1. 学校的小程序是青柚管的\n2. 不招零基础\n\n说是不招，还是抱着试一试的心态，去投了个ui岗，毕竟当时恰好在学原型。结果石沉大海，冒得回应。\n\n大一上死命学会c之后，大一下堕落了起来，直到有天看到阿里云服务器打折，心血来潮，和好基友Roc买了一台49一年的小服务器，搭博客玩。\n\n没服务器的时候就在折腾jekyll和各种pages了，有了服务器之后终于上了心心念的wordpress，然后就是折腾wp各种奇奇怪怪的东西，然后发现有个好东西叫docker，于是又拿docker部署各种各样的服务。我记得最多的时候，部署了博客，gitee，一个ftp服务器，还连了163邮箱发报警。对于一个1核心2m带宽的服务器来说，压力还是很大了哈哈哈。对了，一开始是用宝塔面板，开始还觉得挺方便的，后来lnmp的p就开始出各种各样的问题。这时候就发现了自动部署忽视细节是个多么难搞的问题。从此决定手动搭各种环境。然后又经历了几次服务器重置之后，我和Roc决定还是把网页部署到gitlab page上，毕竟写好md文档然后直接push，确实比wp舒服多了。\n\n接下来在大一结束的那个暑假，我又一次想起了青柚的招新，这次我决定报个运维岗位试试。本想着会遇到各种可能的高难度问题，还提心吊胆地做了各种准备，结果似乎没有遇到太大困难就进来了。进来之后才发现青柚已经很久没有运维了。上一届的运维是一位后端，再往前是一位运营。也确实，运维这份活在小公司本就是可有可无的，更何况这么个工作室呢？不过我还是很喜欢这份活的，毕竟能看着各种软件稳稳的运行，不用想破脑袋实现各种奇奇怪怪的需求，其实也不错（手动狗头）。\n\n就在今天，学校的出入校小程序上线了。这个项目一个月前就开始了，当时我也被拉进了这个项目的群里，然后被告知学校找了外面的运维，用了大公司的serverless。这一个月以来都是平稳推进，直到前天，突然改了需求，又要求昨天就要上线，整个工作室的人都被拉了进来，并且核心人员从前天晚上七点一直加班到昨天中午十一二点。当所有人都在加班的时候，一个运维坐在工作室的正中间，写着自己满是bug的minishell（狗头）。\n\n好吧，其实几天前我几天前刚接到了要管理学校镜像站的任务，一个python+nginx的小组合，拉取镜像用了python写的mirrord工具，好像是北京外国语还是北京交大的（我估计再往上查一下会发现是清华的，此时，清华用的go），然后再在nginx里面配置下转发就行。但是仔细考虑下自己吧，好像python不咋熟练（那必然），go吧肯定不会，最要命的是线程相关的问题，基本是只知道概念（甚至不清楚），略知一二那种。所以想写出点什么，一时半会恐怕没办法，所以现在抓紧学操作系统，把线程方面搞清楚了，再找个趁手的工具，把镜像站的任务系统化一点，争取做成一个平台。\n\n我又想起前天晚上加班的场景，虽然我啥都没干，但我还是挺喜欢这种氛围的。希望能在这里写点什么，写点什么，最后再写点什么。（老谜语人了）\n\n","source":"_posts/Qingyou-1.md","raw":"---\ntitle: Qingyou_1\ndate: 2021-10-27 09:01:06\ncategories: life\ntags:\n---\n# 青柚的这点事（1）\n\n大一开学的时候被学校拉去听优秀学生讲座。然后青柚的指导老师上去宣传了一波，我就记得两件事：\n\n1. 学校的小程序是青柚管的\n2. 不招零基础\n\n说是不招，还是抱着试一试的心态，去投了个ui岗，毕竟当时恰好在学原型。结果石沉大海，冒得回应。\n\n大一上死命学会c之后，大一下堕落了起来，直到有天看到阿里云服务器打折，心血来潮，和好基友Roc买了一台49一年的小服务器，搭博客玩。\n\n没服务器的时候就在折腾jekyll和各种pages了，有了服务器之后终于上了心心念的wordpress，然后就是折腾wp各种奇奇怪怪的东西，然后发现有个好东西叫docker，于是又拿docker部署各种各样的服务。我记得最多的时候，部署了博客，gitee，一个ftp服务器，还连了163邮箱发报警。对于一个1核心2m带宽的服务器来说，压力还是很大了哈哈哈。对了，一开始是用宝塔面板，开始还觉得挺方便的，后来lnmp的p就开始出各种各样的问题。这时候就发现了自动部署忽视细节是个多么难搞的问题。从此决定手动搭各种环境。然后又经历了几次服务器重置之后，我和Roc决定还是把网页部署到gitlab page上，毕竟写好md文档然后直接push，确实比wp舒服多了。\n\n接下来在大一结束的那个暑假，我又一次想起了青柚的招新，这次我决定报个运维岗位试试。本想着会遇到各种可能的高难度问题，还提心吊胆地做了各种准备，结果似乎没有遇到太大困难就进来了。进来之后才发现青柚已经很久没有运维了。上一届的运维是一位后端，再往前是一位运营。也确实，运维这份活在小公司本就是可有可无的，更何况这么个工作室呢？不过我还是很喜欢这份活的，毕竟能看着各种软件稳稳的运行，不用想破脑袋实现各种奇奇怪怪的需求，其实也不错（手动狗头）。\n\n就在今天，学校的出入校小程序上线了。这个项目一个月前就开始了，当时我也被拉进了这个项目的群里，然后被告知学校找了外面的运维，用了大公司的serverless。这一个月以来都是平稳推进，直到前天，突然改了需求，又要求昨天就要上线，整个工作室的人都被拉了进来，并且核心人员从前天晚上七点一直加班到昨天中午十一二点。当所有人都在加班的时候，一个运维坐在工作室的正中间，写着自己满是bug的minishell（狗头）。\n\n好吧，其实几天前我几天前刚接到了要管理学校镜像站的任务，一个python+nginx的小组合，拉取镜像用了python写的mirrord工具，好像是北京外国语还是北京交大的（我估计再往上查一下会发现是清华的，此时，清华用的go），然后再在nginx里面配置下转发就行。但是仔细考虑下自己吧，好像python不咋熟练（那必然），go吧肯定不会，最要命的是线程相关的问题，基本是只知道概念（甚至不清楚），略知一二那种。所以想写出点什么，一时半会恐怕没办法，所以现在抓紧学操作系统，把线程方面搞清楚了，再找个趁手的工具，把镜像站的任务系统化一点，争取做成一个平台。\n\n我又想起前天晚上加班的场景，虽然我啥都没干，但我还是挺喜欢这种氛围的。希望能在这里写点什么，写点什么，最后再写点什么。（老谜语人了）\n\n","slug":"Qingyou-1","published":1,"updated":"2021-10-27T05:13:00.307Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckv9h3bhl0005e0ul6ox31j9y","content":"<h1 id=\"青柚的这点事（1）\"><a href=\"#青柚的这点事（1）\" class=\"headerlink\" title=\"青柚的这点事（1）\"></a>青柚的这点事（1）</h1><p>大一开学的时候被学校拉去听优秀学生讲座。然后青柚的指导老师上去宣传了一波，我就记得两件事：</p>\n<ol>\n<li>学校的小程序是青柚管的</li>\n<li>不招零基础</li>\n</ol>\n<p>说是不招，还是抱着试一试的心态，去投了个ui岗，毕竟当时恰好在学原型。结果石沉大海，冒得回应。</p>\n<p>大一上死命学会c之后，大一下堕落了起来，直到有天看到阿里云服务器打折，心血来潮，和好基友Roc买了一台49一年的小服务器，搭博客玩。</p>\n<p>没服务器的时候就在折腾jekyll和各种pages了，有了服务器之后终于上了心心念的wordpress，然后就是折腾wp各种奇奇怪怪的东西，然后发现有个好东西叫docker，于是又拿docker部署各种各样的服务。我记得最多的时候，部署了博客，gitee，一个ftp服务器，还连了163邮箱发报警。对于一个1核心2m带宽的服务器来说，压力还是很大了哈哈哈。对了，一开始是用宝塔面板，开始还觉得挺方便的，后来lnmp的p就开始出各种各样的问题。这时候就发现了自动部署忽视细节是个多么难搞的问题。从此决定手动搭各种环境。然后又经历了几次服务器重置之后，我和Roc决定还是把网页部署到gitlab page上，毕竟写好md文档然后直接push，确实比wp舒服多了。</p>\n<p>接下来在大一结束的那个暑假，我又一次想起了青柚的招新，这次我决定报个运维岗位试试。本想着会遇到各种可能的高难度问题，还提心吊胆地做了各种准备，结果似乎没有遇到太大困难就进来了。进来之后才发现青柚已经很久没有运维了。上一届的运维是一位后端，再往前是一位运营。也确实，运维这份活在小公司本就是可有可无的，更何况这么个工作室呢？不过我还是很喜欢这份活的，毕竟能看着各种软件稳稳的运行，不用想破脑袋实现各种奇奇怪怪的需求，其实也不错（手动狗头）。</p>\n<p>就在今天，学校的出入校小程序上线了。这个项目一个月前就开始了，当时我也被拉进了这个项目的群里，然后被告知学校找了外面的运维，用了大公司的serverless。这一个月以来都是平稳推进，直到前天，突然改了需求，又要求昨天就要上线，整个工作室的人都被拉了进来，并且核心人员从前天晚上七点一直加班到昨天中午十一二点。当所有人都在加班的时候，一个运维坐在工作室的正中间，写着自己满是bug的minishell（狗头）。</p>\n<p>好吧，其实几天前我几天前刚接到了要管理学校镜像站的任务，一个python+nginx的小组合，拉取镜像用了python写的mirrord工具，好像是北京外国语还是北京交大的（我估计再往上查一下会发现是清华的，此时，清华用的go），然后再在nginx里面配置下转发就行。但是仔细考虑下自己吧，好像python不咋熟练（那必然），go吧肯定不会，最要命的是线程相关的问题，基本是只知道概念（甚至不清楚），略知一二那种。所以想写出点什么，一时半会恐怕没办法，所以现在抓紧学操作系统，把线程方面搞清楚了，再找个趁手的工具，把镜像站的任务系统化一点，争取做成一个平台。</p>\n<p>我又想起前天晚上加班的场景，虽然我啥都没干，但我还是挺喜欢这种氛围的。希望能在这里写点什么，写点什么，最后再写点什么。（老谜语人了）</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"青柚的这点事（1）\"><a href=\"#青柚的这点事（1）\" class=\"headerlink\" title=\"青柚的这点事（1）\"></a>青柚的这点事（1）</h1><p>大一开学的时候被学校拉去听优秀学生讲座。然后青柚的指导老师上去宣传了一波，我就记得两件事：</p>\n<ol>\n<li>学校的小程序是青柚管的</li>\n<li>不招零基础</li>\n</ol>\n<p>说是不招，还是抱着试一试的心态，去投了个ui岗，毕竟当时恰好在学原型。结果石沉大海，冒得回应。</p>\n<p>大一上死命学会c之后，大一下堕落了起来，直到有天看到阿里云服务器打折，心血来潮，和好基友Roc买了一台49一年的小服务器，搭博客玩。</p>\n<p>没服务器的时候就在折腾jekyll和各种pages了，有了服务器之后终于上了心心念的wordpress，然后就是折腾wp各种奇奇怪怪的东西，然后发现有个好东西叫docker，于是又拿docker部署各种各样的服务。我记得最多的时候，部署了博客，gitee，一个ftp服务器，还连了163邮箱发报警。对于一个1核心2m带宽的服务器来说，压力还是很大了哈哈哈。对了，一开始是用宝塔面板，开始还觉得挺方便的，后来lnmp的p就开始出各种各样的问题。这时候就发现了自动部署忽视细节是个多么难搞的问题。从此决定手动搭各种环境。然后又经历了几次服务器重置之后，我和Roc决定还是把网页部署到gitlab page上，毕竟写好md文档然后直接push，确实比wp舒服多了。</p>\n<p>接下来在大一结束的那个暑假，我又一次想起了青柚的招新，这次我决定报个运维岗位试试。本想着会遇到各种可能的高难度问题，还提心吊胆地做了各种准备，结果似乎没有遇到太大困难就进来了。进来之后才发现青柚已经很久没有运维了。上一届的运维是一位后端，再往前是一位运营。也确实，运维这份活在小公司本就是可有可无的，更何况这么个工作室呢？不过我还是很喜欢这份活的，毕竟能看着各种软件稳稳的运行，不用想破脑袋实现各种奇奇怪怪的需求，其实也不错（手动狗头）。</p>\n<p>就在今天，学校的出入校小程序上线了。这个项目一个月前就开始了，当时我也被拉进了这个项目的群里，然后被告知学校找了外面的运维，用了大公司的serverless。这一个月以来都是平稳推进，直到前天，突然改了需求，又要求昨天就要上线，整个工作室的人都被拉了进来，并且核心人员从前天晚上七点一直加班到昨天中午十一二点。当所有人都在加班的时候，一个运维坐在工作室的正中间，写着自己满是bug的minishell（狗头）。</p>\n<p>好吧，其实几天前我几天前刚接到了要管理学校镜像站的任务，一个python+nginx的小组合，拉取镜像用了python写的mirrord工具，好像是北京外国语还是北京交大的（我估计再往上查一下会发现是清华的，此时，清华用的go），然后再在nginx里面配置下转发就行。但是仔细考虑下自己吧，好像python不咋熟练（那必然），go吧肯定不会，最要命的是线程相关的问题，基本是只知道概念（甚至不清楚），略知一二那种。所以想写出点什么，一时半会恐怕没办法，所以现在抓紧学操作系统，把线程方面搞清楚了，再找个趁手的工具，把镜像站的任务系统化一点，争取做成一个平台。</p>\n<p>我又想起前天晚上加班的场景，虽然我啥都没干，但我还是挺喜欢这种氛围的。希望能在这里写点什么，写点什么，最后再写点什么。（老谜语人了）</p>\n"},{"author":"kawhicurry","title":"Magic-Macro","date":"2021-11-07T12:28:58.000Z","_content":"\n# The magic of macro\n最近在写c，遇到了这样一段逻辑，要根据接受的字符串\n```\n# The magic of macro\n\n最近在写c，遇到了这样一段逻辑，根据要接受的字符串，比如`name=ubuntu`来在结构体mirror中找到对应的mirror.name进行赋值，一开始是这样设计的：\n\n```c\nstatic const char* PARA_LIST[MAX_ARG_NUM] = {\"name\", \"cmd\", \"arg\", \"url\", \"timeout\"};\n//然后对'='前的值与上述值匹配，得到一个id，如name的id为0\nswitch(i){\n    case 0:\n      if (para_len > MAX_NAME_LEN) {\n        printf(\"name too long!\");\n        return;\n      }\n      memcpy(mirror->name, parameter + 1, MAX_NAME_LEN);\n      break;\n    case 1:\n      //...\n    case 4:\n      //...  \n}\n//然后switch进行匹配，在switch中都需要先做长度判断，再给结构体mirror赋值\n```\n\n对于每个case来说，这样的事情都要做一遍，而其中除了struct中的元素不同之外，其他基本都完全一致（除了最后一个timeout），于是我就想简化这个过程。一开始，我想到了写n个不同的函数，这样我就可以在每个case中用一个函数替换，但仔细一想，这样还不是要给每个case写一个函数。这时候我想起了宏，上网查找一番后发现的宏的拼接功能。于是我写出了这个：\n\n```c\n#define set_mirror(the_mirror, element, parameter)            \\\n  {                                                           \\\n    if (!strcmp(#element, \"timeout\")) {                       \\\n      the_mirror.timeout_len = strlen(parameter);             \\\n    }                                                         \\\n    memset(the_mirror.element, 0, strlen(parameter) + 1);     \\\n    memcpy(the_mirror.element, parameter, sizeof(parameter)); \\\n  }\n```\n\n其中的`#element`,会讲element替换成字符串，而`##`可以将set_mirror的参数和后面的内容进行拼接（在后面的版本有示范）。上面这个版本已经可以替换赋值的功能了，但还没对长度进行考察。然后我脑子一抽，写了个`#define len_set_mirror` 其实就是上面`set_mirror`加一个参数，然后再调用`set_mirror`的宏。当时是记住了宏的一种“延迟”的机制，可以在有限次数内对宏进行一个嵌套。后面发现length可以直接从parameter获取，于是就将两个宏合并成了一个：\n\n```c\n#define set_mirror(p_mirror, element, parameter, id)               \\\n  do {                                                             \\\n    if (length(parameter) > MAX_##element##_LEN) {                 \\\n      printf(\"##element too long!\");                               \\\n      return 0;                                                    \\\n    }                                                              \\\n    if (!strcmp(#element, \"timeout\")) {                            \\\n      (p_mirror)->timeout_len = length(parameter);                 \\\n    }                                                              \\\n    memset((p_mirror)->element, '\\0', length(parameter) + 1);      \\\n    memcpy((p_mirror)->element, parameter, length(parameter) - 1); \\\n    ((p_mirror)->available) << id;                                 \\\n  } while (0)\n\n```\n\n这次成功将所有功能合并了，并且学到了用do...while(0)来提高宏的安全性（其实我也想到了用大括号的方法来避免，但确实do...while(0)是一个更好的方案。这种写法之后我只需在case中写两行：\n\n```c\n    case 0:\n      set_mirror(p_mirror, name, parameter, id);\n      break;//break还是老老实实写吧，方便set_mirror复用\n```\n\n其实在第一个宏之前，我还写了个在宏中构造变量来接受值的做法，但我发现完全没有必要，毕竟传递进来的值都应该可以被直接操作的（宏展开后直接获得变量）。由此也引出一条经验，大可不必在宏中定义新变量来处理数据。\n\n我对宏最大的印象就是文本替换，关于上面这段逻辑，switch还可以进一步优化。而对于整个c来说，宏是底层库的基础，我后面试图去实现一个strlen函数时，发现这玩意就是靠宏和汇编来实现的，而像c中的attribute，__VA_ARGS__(可变参数)，更有一片天地。甚至可以做逻辑运算，过于离谱了。\n\n结论：宏是魔法，这是我第一次真正近距离接触它，它真的是c的魔法。","source":"_posts/Magic-Macro.md","raw":"---\nauthor: kawhicurry\ntitle: Magic-Macro\ncategories:\n- Language\ndate: 2021-11-07 20:28:58\ntags: C\n---\n\n# The magic of macro\n最近在写c，遇到了这样一段逻辑，要根据接受的字符串\n```\n# The magic of macro\n\n最近在写c，遇到了这样一段逻辑，根据要接受的字符串，比如`name=ubuntu`来在结构体mirror中找到对应的mirror.name进行赋值，一开始是这样设计的：\n\n```c\nstatic const char* PARA_LIST[MAX_ARG_NUM] = {\"name\", \"cmd\", \"arg\", \"url\", \"timeout\"};\n//然后对'='前的值与上述值匹配，得到一个id，如name的id为0\nswitch(i){\n    case 0:\n      if (para_len > MAX_NAME_LEN) {\n        printf(\"name too long!\");\n        return;\n      }\n      memcpy(mirror->name, parameter + 1, MAX_NAME_LEN);\n      break;\n    case 1:\n      //...\n    case 4:\n      //...  \n}\n//然后switch进行匹配，在switch中都需要先做长度判断，再给结构体mirror赋值\n```\n\n对于每个case来说，这样的事情都要做一遍，而其中除了struct中的元素不同之外，其他基本都完全一致（除了最后一个timeout），于是我就想简化这个过程。一开始，我想到了写n个不同的函数，这样我就可以在每个case中用一个函数替换，但仔细一想，这样还不是要给每个case写一个函数。这时候我想起了宏，上网查找一番后发现的宏的拼接功能。于是我写出了这个：\n\n```c\n#define set_mirror(the_mirror, element, parameter)            \\\n  {                                                           \\\n    if (!strcmp(#element, \"timeout\")) {                       \\\n      the_mirror.timeout_len = strlen(parameter);             \\\n    }                                                         \\\n    memset(the_mirror.element, 0, strlen(parameter) + 1);     \\\n    memcpy(the_mirror.element, parameter, sizeof(parameter)); \\\n  }\n```\n\n其中的`#element`,会讲element替换成字符串，而`##`可以将set_mirror的参数和后面的内容进行拼接（在后面的版本有示范）。上面这个版本已经可以替换赋值的功能了，但还没对长度进行考察。然后我脑子一抽，写了个`#define len_set_mirror` 其实就是上面`set_mirror`加一个参数，然后再调用`set_mirror`的宏。当时是记住了宏的一种“延迟”的机制，可以在有限次数内对宏进行一个嵌套。后面发现length可以直接从parameter获取，于是就将两个宏合并成了一个：\n\n```c\n#define set_mirror(p_mirror, element, parameter, id)               \\\n  do {                                                             \\\n    if (length(parameter) > MAX_##element##_LEN) {                 \\\n      printf(\"##element too long!\");                               \\\n      return 0;                                                    \\\n    }                                                              \\\n    if (!strcmp(#element, \"timeout\")) {                            \\\n      (p_mirror)->timeout_len = length(parameter);                 \\\n    }                                                              \\\n    memset((p_mirror)->element, '\\0', length(parameter) + 1);      \\\n    memcpy((p_mirror)->element, parameter, length(parameter) - 1); \\\n    ((p_mirror)->available) << id;                                 \\\n  } while (0)\n\n```\n\n这次成功将所有功能合并了，并且学到了用do...while(0)来提高宏的安全性（其实我也想到了用大括号的方法来避免，但确实do...while(0)是一个更好的方案。这种写法之后我只需在case中写两行：\n\n```c\n    case 0:\n      set_mirror(p_mirror, name, parameter, id);\n      break;//break还是老老实实写吧，方便set_mirror复用\n```\n\n其实在第一个宏之前，我还写了个在宏中构造变量来接受值的做法，但我发现完全没有必要，毕竟传递进来的值都应该可以被直接操作的（宏展开后直接获得变量）。由此也引出一条经验，大可不必在宏中定义新变量来处理数据。\n\n我对宏最大的印象就是文本替换，关于上面这段逻辑，switch还可以进一步优化。而对于整个c来说，宏是底层库的基础，我后面试图去实现一个strlen函数时，发现这玩意就是靠宏和汇编来实现的，而像c中的attribute，__VA_ARGS__(可变参数)，更有一片天地。甚至可以做逻辑运算，过于离谱了。\n\n结论：宏是魔法，这是我第一次真正近距离接触它，它真的是c的魔法。","slug":"Magic-Macro","published":1,"updated":"2021-11-07T13:14:28.751Z","_id":"ckvp97s0y0000a4ul9ha3c995","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"The-magic-of-macro\"><a href=\"#The-magic-of-macro\" class=\"headerlink\" title=\"The magic of macro\"></a>The magic of macro</h1><p>最近在写c，遇到了这样一段逻辑，要根据接受的字符串</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># The magic of macro</span><br><span class=\"line\"></span><br><span class=\"line\">最近在写c，遇到了这样一段逻辑，根据要接受的字符串，比如`name=ubuntu`来在结构体mirror中找到对应的mirror.name进行赋值，一开始是这样设计的：</span><br><span class=\"line\"></span><br><span class=\"line\">```c</span><br><span class=\"line\">static const char* PARA_LIST[MAX_ARG_NUM] = &#123;&quot;name&quot;, &quot;cmd&quot;, &quot;arg&quot;, &quot;url&quot;, &quot;timeout&quot;&#125;;</span><br><span class=\"line\">//然后对&#x27;=&#x27;前的值与上述值匹配，得到一个id，如name的id为0</span><br><span class=\"line\">switch(i)&#123;</span><br><span class=\"line\">    case 0:</span><br><span class=\"line\">      if (para_len &gt; MAX_NAME_LEN) &#123;</span><br><span class=\"line\">        printf(&quot;name too long!&quot;);</span><br><span class=\"line\">        return;</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">      memcpy(mirror-&gt;name, parameter + 1, MAX_NAME_LEN);</span><br><span class=\"line\">      break;</span><br><span class=\"line\">    case 1:</span><br><span class=\"line\">      //...</span><br><span class=\"line\">    case 4:</span><br><span class=\"line\">      //...  </span><br><span class=\"line\">&#125;</span><br><span class=\"line\">//然后switch进行匹配，在switch中都需要先做长度判断，再给结构体mirror赋值</span><br></pre></td></tr></table></figure>\n\n<p>对于每个case来说，这样的事情都要做一遍，而其中除了struct中的元素不同之外，其他基本都完全一致（除了最后一个timeout），于是我就想简化这个过程。一开始，我想到了写n个不同的函数，这样我就可以在每个case中用一个函数替换，但仔细一想，这样还不是要给每个case写一个函数。这时候我想起了宏，上网查找一番后发现的宏的拼接功能。于是我写出了这个：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span> set_mirror(the_mirror, element, parameter)            \\</span></span><br><span class=\"line\"><span class=\"meta\">  &#123;                                                           \\</span></span><br><span class=\"line\"><span class=\"meta\">    <span class=\"meta-keyword\">if</span> (!strcmp(#element, <span class=\"meta-string\">&quot;timeout&quot;</span>)) &#123;                       \\</span></span><br><span class=\"line\"><span class=\"meta\">      the_mirror.timeout_len = strlen(parameter);             \\</span></span><br><span class=\"line\"><span class=\"meta\">    &#125;                                                         \\</span></span><br><span class=\"line\"><span class=\"meta\">    memset(the_mirror.element, 0, strlen(parameter) + 1);     \\</span></span><br><span class=\"line\"><span class=\"meta\">    memcpy(the_mirror.element, parameter, sizeof(parameter)); \\</span></span><br><span class=\"line\"><span class=\"meta\">  &#125;</span></span><br></pre></td></tr></table></figure>\n\n<p>其中的<code>#element</code>,会讲element替换成字符串，而<code>##</code>可以将set_mirror的参数和后面的内容进行拼接（在后面的版本有示范）。上面这个版本已经可以替换赋值的功能了，但还没对长度进行考察。然后我脑子一抽，写了个<code>#define len_set_mirror</code> 其实就是上面<code>set_mirror</code>加一个参数，然后再调用<code>set_mirror</code>的宏。当时是记住了宏的一种“延迟”的机制，可以在有限次数内对宏进行一个嵌套。后面发现length可以直接从parameter获取，于是就将两个宏合并成了一个：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span> set_mirror(p_mirror, element, parameter, id)               \\</span></span><br><span class=\"line\"><span class=\"meta\">  do &#123;                                                             \\</span></span><br><span class=\"line\"><span class=\"meta\">    <span class=\"meta-keyword\">if</span> (length(parameter) &gt; MAX_##element##_LEN) &#123;                 \\</span></span><br><span class=\"line\"><span class=\"meta\">      printf(<span class=\"meta-string\">&quot;##element too long!&quot;</span>);                               \\</span></span><br><span class=\"line\"><span class=\"meta\">      return 0;                                                    \\</span></span><br><span class=\"line\"><span class=\"meta\">    &#125;                                                              \\</span></span><br><span class=\"line\"><span class=\"meta\">    <span class=\"meta-keyword\">if</span> (!strcmp(#element, <span class=\"meta-string\">&quot;timeout&quot;</span>)) &#123;                            \\</span></span><br><span class=\"line\"><span class=\"meta\">      (p_mirror)-&gt;timeout_len = length(parameter);                 \\</span></span><br><span class=\"line\"><span class=\"meta\">    &#125;                                                              \\</span></span><br><span class=\"line\"><span class=\"meta\">    memset((p_mirror)-&gt;element, <span class=\"meta-string\">&#x27;\\0&#x27;</span>, length(parameter) + 1);      \\</span></span><br><span class=\"line\"><span class=\"meta\">    memcpy((p_mirror)-&gt;element, parameter, length(parameter) - 1); \\</span></span><br><span class=\"line\"><span class=\"meta\">    ((p_mirror)-&gt;available) &lt;&lt; id;                                 \\</span></span><br><span class=\"line\"><span class=\"meta\">  &#125; while (0)</span></span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>这次成功将所有功能合并了，并且学到了用do…while(0)来提高宏的安全性（其实我也想到了用大括号的方法来避免，但确实do…while(0)是一个更好的方案。这种写法之后我只需在case中写两行：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">case</span> <span class=\"number\">0</span>:</span><br><span class=\"line\">  set_mirror(p_mirror, name, parameter, id);</span><br><span class=\"line\">  <span class=\"keyword\">break</span>;<span class=\"comment\">//break还是老老实实写吧，方便set_mirror复用</span></span><br></pre></td></tr></table></figure>\n\n<p>其实在第一个宏之前，我还写了个在宏中构造变量来接受值的做法，但我发现完全没有必要，毕竟传递进来的值都应该可以被直接操作的（宏展开后直接获得变量）。由此也引出一条经验，大可不必在宏中定义新变量来处理数据。</p>\n<p>我对宏最大的印象就是文本替换，关于上面这段逻辑，switch还可以进一步优化。而对于整个c来说，宏是底层库的基础，我后面试图去实现一个strlen函数时，发现这玩意就是靠宏和汇编来实现的，而像c中的attribute，<strong>VA_ARGS</strong>(可变参数)，更有一片天地。甚至可以做逻辑运算，过于离谱了。</p>\n<p>结论：宏是魔法，这是我第一次真正近距离接触它，它真的是c的魔法。</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"The-magic-of-macro\"><a href=\"#The-magic-of-macro\" class=\"headerlink\" title=\"The magic of macro\"></a>The magic of macro</h1><p>最近在写c，遇到了这样一段逻辑，要根据接受的字符串</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># The magic of macro</span><br><span class=\"line\"></span><br><span class=\"line\">最近在写c，遇到了这样一段逻辑，根据要接受的字符串，比如`name=ubuntu`来在结构体mirror中找到对应的mirror.name进行赋值，一开始是这样设计的：</span><br><span class=\"line\"></span><br><span class=\"line\">```c</span><br><span class=\"line\">static const char* PARA_LIST[MAX_ARG_NUM] = &#123;&quot;name&quot;, &quot;cmd&quot;, &quot;arg&quot;, &quot;url&quot;, &quot;timeout&quot;&#125;;</span><br><span class=\"line\">//然后对&#x27;=&#x27;前的值与上述值匹配，得到一个id，如name的id为0</span><br><span class=\"line\">switch(i)&#123;</span><br><span class=\"line\">    case 0:</span><br><span class=\"line\">      if (para_len &gt; MAX_NAME_LEN) &#123;</span><br><span class=\"line\">        printf(&quot;name too long!&quot;);</span><br><span class=\"line\">        return;</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">      memcpy(mirror-&gt;name, parameter + 1, MAX_NAME_LEN);</span><br><span class=\"line\">      break;</span><br><span class=\"line\">    case 1:</span><br><span class=\"line\">      //...</span><br><span class=\"line\">    case 4:</span><br><span class=\"line\">      //...  </span><br><span class=\"line\">&#125;</span><br><span class=\"line\">//然后switch进行匹配，在switch中都需要先做长度判断，再给结构体mirror赋值</span><br></pre></td></tr></table></figure>\n\n<p>对于每个case来说，这样的事情都要做一遍，而其中除了struct中的元素不同之外，其他基本都完全一致（除了最后一个timeout），于是我就想简化这个过程。一开始，我想到了写n个不同的函数，这样我就可以在每个case中用一个函数替换，但仔细一想，这样还不是要给每个case写一个函数。这时候我想起了宏，上网查找一番后发现的宏的拼接功能。于是我写出了这个：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span> set_mirror(the_mirror, element, parameter)            \\</span></span><br><span class=\"line\"><span class=\"meta\">  &#123;                                                           \\</span></span><br><span class=\"line\"><span class=\"meta\">    <span class=\"meta-keyword\">if</span> (!strcmp(#element, <span class=\"meta-string\">&quot;timeout&quot;</span>)) &#123;                       \\</span></span><br><span class=\"line\"><span class=\"meta\">      the_mirror.timeout_len = strlen(parameter);             \\</span></span><br><span class=\"line\"><span class=\"meta\">    &#125;                                                         \\</span></span><br><span class=\"line\"><span class=\"meta\">    memset(the_mirror.element, 0, strlen(parameter) + 1);     \\</span></span><br><span class=\"line\"><span class=\"meta\">    memcpy(the_mirror.element, parameter, sizeof(parameter)); \\</span></span><br><span class=\"line\"><span class=\"meta\">  &#125;</span></span><br></pre></td></tr></table></figure>\n\n<p>其中的<code>#element</code>,会讲element替换成字符串，而<code>##</code>可以将set_mirror的参数和后面的内容进行拼接（在后面的版本有示范）。上面这个版本已经可以替换赋值的功能了，但还没对长度进行考察。然后我脑子一抽，写了个<code>#define len_set_mirror</code> 其实就是上面<code>set_mirror</code>加一个参数，然后再调用<code>set_mirror</code>的宏。当时是记住了宏的一种“延迟”的机制，可以在有限次数内对宏进行一个嵌套。后面发现length可以直接从parameter获取，于是就将两个宏合并成了一个：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span> set_mirror(p_mirror, element, parameter, id)               \\</span></span><br><span class=\"line\"><span class=\"meta\">  do &#123;                                                             \\</span></span><br><span class=\"line\"><span class=\"meta\">    <span class=\"meta-keyword\">if</span> (length(parameter) &gt; MAX_##element##_LEN) &#123;                 \\</span></span><br><span class=\"line\"><span class=\"meta\">      printf(<span class=\"meta-string\">&quot;##element too long!&quot;</span>);                               \\</span></span><br><span class=\"line\"><span class=\"meta\">      return 0;                                                    \\</span></span><br><span class=\"line\"><span class=\"meta\">    &#125;                                                              \\</span></span><br><span class=\"line\"><span class=\"meta\">    <span class=\"meta-keyword\">if</span> (!strcmp(#element, <span class=\"meta-string\">&quot;timeout&quot;</span>)) &#123;                            \\</span></span><br><span class=\"line\"><span class=\"meta\">      (p_mirror)-&gt;timeout_len = length(parameter);                 \\</span></span><br><span class=\"line\"><span class=\"meta\">    &#125;                                                              \\</span></span><br><span class=\"line\"><span class=\"meta\">    memset((p_mirror)-&gt;element, <span class=\"meta-string\">&#x27;\\0&#x27;</span>, length(parameter) + 1);      \\</span></span><br><span class=\"line\"><span class=\"meta\">    memcpy((p_mirror)-&gt;element, parameter, length(parameter) - 1); \\</span></span><br><span class=\"line\"><span class=\"meta\">    ((p_mirror)-&gt;available) &lt;&lt; id;                                 \\</span></span><br><span class=\"line\"><span class=\"meta\">  &#125; while (0)</span></span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>这次成功将所有功能合并了，并且学到了用do…while(0)来提高宏的安全性（其实我也想到了用大括号的方法来避免，但确实do…while(0)是一个更好的方案。这种写法之后我只需在case中写两行：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">case</span> <span class=\"number\">0</span>:</span><br><span class=\"line\">  set_mirror(p_mirror, name, parameter, id);</span><br><span class=\"line\">  <span class=\"keyword\">break</span>;<span class=\"comment\">//break还是老老实实写吧，方便set_mirror复用</span></span><br></pre></td></tr></table></figure>\n\n<p>其实在第一个宏之前，我还写了个在宏中构造变量来接受值的做法，但我发现完全没有必要，毕竟传递进来的值都应该可以被直接操作的（宏展开后直接获得变量）。由此也引出一条经验，大可不必在宏中定义新变量来处理数据。</p>\n<p>我对宏最大的印象就是文本替换，关于上面这段逻辑，switch还可以进一步优化。而对于整个c来说，宏是底层库的基础，我后面试图去实现一个strlen函数时，发现这玩意就是靠宏和汇编来实现的，而像c中的attribute，<strong>VA_ARGS</strong>(可变参数)，更有一片天地。甚至可以做逻辑运算，过于离谱了。</p>\n<p>结论：宏是魔法，这是我第一次真正近距离接触它，它真的是c的魔法。</p>\n"},{"author":"kawhicurry","title":"log-a-git-error","date":"2021-11-10T12:01:01.000Z","_content":"\nWhen I tried to clone a repo from self-built gitlab. I met a error like this：\n\n```bash\n$> git clone https://git.qingyou.ren/KawhiCurry/ansible.git  Cloning into 'ansible'...\nfatal: unable to access 'https://git.qingyou.ren/KawhiCurry/ansible.git/': Failed to connect to 127.0.0.1 port 7890: Connection refused\n```\n\nAnyway, 7890 refuse me. Finally, I got this: [cnblogs](https://www.cnblogs.com/lfri/p/15377383.html)\n\nSeems my proxy(or vpn?)ruin it. It leads my git somewhere strange.\n\nrecord the operation here.\n\n```bash\ngit config --global -l\ngit config --global -e\n//delete or comment on the lines about port\n```\n\n","source":"_posts/log-a-git-error.md","raw":"---\nauthor: kawhicurry\ntitle: log-a-git-error\ncategories: tool\ndate: 2021-11-10 20:01:01\ntags: git\n---\n\nWhen I tried to clone a repo from self-built gitlab. I met a error like this：\n\n```bash\n$> git clone https://git.qingyou.ren/KawhiCurry/ansible.git  Cloning into 'ansible'...\nfatal: unable to access 'https://git.qingyou.ren/KawhiCurry/ansible.git/': Failed to connect to 127.0.0.1 port 7890: Connection refused\n```\n\nAnyway, 7890 refuse me. Finally, I got this: [cnblogs](https://www.cnblogs.com/lfri/p/15377383.html)\n\nSeems my proxy(or vpn?)ruin it. It leads my git somewhere strange.\n\nrecord the operation here.\n\n```bash\ngit config --global -l\ngit config --global -e\n//delete or comment on the lines about port\n```\n\n","slug":"log-a-git-error","published":1,"updated":"2021-11-10T12:11:45.333Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckvthffej0000bkul3r911bwx","content":"<p>When I tried to clone a repo from self-built gitlab. I met a error like this：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$&gt; git <span class=\"built_in\">clone</span> https://git.qingyou.ren/KawhiCurry/ansible.git  Cloning into <span class=\"string\">&#x27;ansible&#x27;</span>...</span><br><span class=\"line\">fatal: unable to access <span class=\"string\">&#x27;https://git.qingyou.ren/KawhiCurry/ansible.git/&#x27;</span>: Failed to connect to 127.0.0.1 port 7890: Connection refused</span><br></pre></td></tr></table></figure>\n\n<p>Anyway, 7890 refuse me. Finally, I got this: <a href=\"https://www.cnblogs.com/lfri/p/15377383.html\">cnblogs</a></p>\n<p>Seems my proxy(or vpn?)ruin it. It leads my git somewhere strange.</p>\n<p>record the operation here.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git config --global -l</span><br><span class=\"line\">git config --global -e</span><br><span class=\"line\">//delete or comment on the lines about port</span><br></pre></td></tr></table></figure>\n\n","site":{"data":{}},"excerpt":"","more":"<p>When I tried to clone a repo from self-built gitlab. I met a error like this：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$&gt; git <span class=\"built_in\">clone</span> https://git.qingyou.ren/KawhiCurry/ansible.git  Cloning into <span class=\"string\">&#x27;ansible&#x27;</span>...</span><br><span class=\"line\">fatal: unable to access <span class=\"string\">&#x27;https://git.qingyou.ren/KawhiCurry/ansible.git/&#x27;</span>: Failed to connect to 127.0.0.1 port 7890: Connection refused</span><br></pre></td></tr></table></figure>\n\n<p>Anyway, 7890 refuse me. Finally, I got this: <a href=\"https://www.cnblogs.com/lfri/p/15377383.html\">cnblogs</a></p>\n<p>Seems my proxy(or vpn?)ruin it. It leads my git somewhere strange.</p>\n<p>record the operation here.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git config --global -l</span><br><span class=\"line\">git config --global -e</span><br><span class=\"line\">//delete or comment on the lines about port</span><br></pre></td></tr></table></figure>\n\n"},{"_content":"# 一个软件的诞生\n\n## 开发过程\n\n准备：市场调查、需求分析……\n\n确定方案：技术，平台\n\n开发：\n\n- 设计&前端：界面\n- 后端：业务逻辑\n\n上线：\n\n- 运营：宣传\n- 运维：服务器维护\n\n# 传统的运维方式\n\n把写好的软件部署到服务器上，跑就完事了。\n\n## 如果业务量大了呢？\n\n用一样的方式部署到很多服务器上，跑就完事了。\n\n## 有什么问题？\n\n- **必须时刻以最大业务量安排服务器数量**，成本高。\n- 每个公司都要有专职运维人员，招人难\n- 运维人员无论水平高低，所能管理的服务器数量有上限\n- 遇到突发状况，所需运维人员数量陡增，而保持一个大量运维团队需要高成本\n\n# 一种趋势\n\n所需管理的服务器数量庞大，但大部分工作都是重复的。所以……\n\n## CI/CD\n\n持续集成，持续交付，持续部署。让后端开发人员（数量庞大，不乏牛人）来完成运维工作\n\n## Devops\n\n运维开发，专门开发运维工具的人。试图将运维工作尽可能的自动化。\n\n# 另一种趋势\n\n## 虚拟化技术的进步\n\n最初的虚拟化：让windows的应用在mac上跑起来（纯举例），虚拟化的环境具有完整的系统，可以在另一个操作系统上跑起来。在性能上具有极大的开销（就是会很慢）\n\n容器化：让一个应用在一个容器中运行，该容器具有该应用所需的全部环境。一个容器就是一个进程，开销较小，与操作系统兼容良好（主要指linux）\n\n## 容器时代\n\n不再关注各式各样的环境问题，所需要的环境都可以打包成容器，并且可以使用别人打包好的容器。\n\n**docker**:第一个开源容器技术的公司，现在仍然是王者。\n\ndocker的开源使得任何人都可以轻松部署各式各样的服务，因为环境的配置已经不是难题。但是对于企业来说，问题仍然存在：每个服务器上都可以跑好几个容器，就像以前一个服务器上可以跑好几个应用一样。如果有几千台呢？几万台呢？\n\n## 容器编排\n\n能不能让不同的服务器上的容器连成一个整体？kubernetes给出了答案。\n\n**kubernetes**:来自google，简称k8s，容器编排唯一的标准，生态的中心。\n\n允许将多个提供同一服务的容器打包成一个pod（豆荚），将多个服务器设置为一个cluster（集群），由k8s来决定pod在哪台服务器上运行。并且k8s可以在不同服务器上启动相同的pod，当一台服务器出现故障时，k8s迅速在其他服务器上添加故障服务器上运行的pod，从而保证了服务的稳定性。\n\n即成事实：**k8s是生态的中心**\n\n围绕k8s的生态：监控，流水线部署，自动预警，网格化网关，容器化数据库以及**serverless**\n\n*k8s标志着云时代的正式开始*\n\n## 再进一步\n\n如果容器可以方便的创建和销毁，能不能更进一步？\n\n当有请求时才创建容器进行服务（而不是一直等着），请求结束就销毁容器，这便是**Serverless**，来自Amazon（亚马逊）\n\n**Serverless**，无服务器技术，只有有需求的时候才服务。\n\n试想一个秒杀系统，在短暂的几秒内，服务器收到了数以亿记的请求，服务器立刻反应，创建大量容器进行服务，每服务完就立即销毁，把资源留给下一个创建的容器。而在几秒前或几秒后，服务器也许还处于一个“清闲”的状态。当前的serverless按照请求数计费，小公司无需按最大并发量购置服务器，只需直接购买serverless服务。\n\n# 云服务现状\n\n自k8s被推出以后，大公司们成立了CNCF（云原生计算基金会）。示例成员：google、AWS（亚马逊，世界最大的云服务供应商，serverless的领头羊）、RedHat（红帽，世界上最大的服务器软件公司，负责的centos操作系统跑在世界上百分之五十以上，中国百分之八十以上的服务器上）、docker、apache基金会（最成熟的服务器软件apache拥有者）、github、gitlab（二者分别为最大的代码托管网站和最大的开源私有git服务提供商）、华为（独立的鲲鹏架构）。\n\n## 国内环境\n\n- 阿里云：全国最大的云服务供应商，对内为淘宝等提供服务，对外为各类企业提供云服务。\n- 腾讯云：对内有qq、微信、微信小程序等业务。拥有独立的小程序平台。\n- 华为云：有自产鲲鹏服务器，使用与绝大多数服务器不一样的arm架构（大部分服务器包括个人电脑都是amd64，也叫x86-64，但苹果的自研芯片M1是arm）。\n- 七牛云：阿里云出走大佬创办，有一定实力。\n- 青云：一个k8s开源集群管理系统的国内主导者。","source":"_posts/123.md","raw":"# 一个软件的诞生\n\n## 开发过程\n\n准备：市场调查、需求分析……\n\n确定方案：技术，平台\n\n开发：\n\n- 设计&前端：界面\n- 后端：业务逻辑\n\n上线：\n\n- 运营：宣传\n- 运维：服务器维护\n\n# 传统的运维方式\n\n把写好的软件部署到服务器上，跑就完事了。\n\n## 如果业务量大了呢？\n\n用一样的方式部署到很多服务器上，跑就完事了。\n\n## 有什么问题？\n\n- **必须时刻以最大业务量安排服务器数量**，成本高。\n- 每个公司都要有专职运维人员，招人难\n- 运维人员无论水平高低，所能管理的服务器数量有上限\n- 遇到突发状况，所需运维人员数量陡增，而保持一个大量运维团队需要高成本\n\n# 一种趋势\n\n所需管理的服务器数量庞大，但大部分工作都是重复的。所以……\n\n## CI/CD\n\n持续集成，持续交付，持续部署。让后端开发人员（数量庞大，不乏牛人）来完成运维工作\n\n## Devops\n\n运维开发，专门开发运维工具的人。试图将运维工作尽可能的自动化。\n\n# 另一种趋势\n\n## 虚拟化技术的进步\n\n最初的虚拟化：让windows的应用在mac上跑起来（纯举例），虚拟化的环境具有完整的系统，可以在另一个操作系统上跑起来。在性能上具有极大的开销（就是会很慢）\n\n容器化：让一个应用在一个容器中运行，该容器具有该应用所需的全部环境。一个容器就是一个进程，开销较小，与操作系统兼容良好（主要指linux）\n\n## 容器时代\n\n不再关注各式各样的环境问题，所需要的环境都可以打包成容器，并且可以使用别人打包好的容器。\n\n**docker**:第一个开源容器技术的公司，现在仍然是王者。\n\ndocker的开源使得任何人都可以轻松部署各式各样的服务，因为环境的配置已经不是难题。但是对于企业来说，问题仍然存在：每个服务器上都可以跑好几个容器，就像以前一个服务器上可以跑好几个应用一样。如果有几千台呢？几万台呢？\n\n## 容器编排\n\n能不能让不同的服务器上的容器连成一个整体？kubernetes给出了答案。\n\n**kubernetes**:来自google，简称k8s，容器编排唯一的标准，生态的中心。\n\n允许将多个提供同一服务的容器打包成一个pod（豆荚），将多个服务器设置为一个cluster（集群），由k8s来决定pod在哪台服务器上运行。并且k8s可以在不同服务器上启动相同的pod，当一台服务器出现故障时，k8s迅速在其他服务器上添加故障服务器上运行的pod，从而保证了服务的稳定性。\n\n即成事实：**k8s是生态的中心**\n\n围绕k8s的生态：监控，流水线部署，自动预警，网格化网关，容器化数据库以及**serverless**\n\n*k8s标志着云时代的正式开始*\n\n## 再进一步\n\n如果容器可以方便的创建和销毁，能不能更进一步？\n\n当有请求时才创建容器进行服务（而不是一直等着），请求结束就销毁容器，这便是**Serverless**，来自Amazon（亚马逊）\n\n**Serverless**，无服务器技术，只有有需求的时候才服务。\n\n试想一个秒杀系统，在短暂的几秒内，服务器收到了数以亿记的请求，服务器立刻反应，创建大量容器进行服务，每服务完就立即销毁，把资源留给下一个创建的容器。而在几秒前或几秒后，服务器也许还处于一个“清闲”的状态。当前的serverless按照请求数计费，小公司无需按最大并发量购置服务器，只需直接购买serverless服务。\n\n# 云服务现状\n\n自k8s被推出以后，大公司们成立了CNCF（云原生计算基金会）。示例成员：google、AWS（亚马逊，世界最大的云服务供应商，serverless的领头羊）、RedHat（红帽，世界上最大的服务器软件公司，负责的centos操作系统跑在世界上百分之五十以上，中国百分之八十以上的服务器上）、docker、apache基金会（最成熟的服务器软件apache拥有者）、github、gitlab（二者分别为最大的代码托管网站和最大的开源私有git服务提供商）、华为（独立的鲲鹏架构）。\n\n## 国内环境\n\n- 阿里云：全国最大的云服务供应商，对内为淘宝等提供服务，对外为各类企业提供云服务。\n- 腾讯云：对内有qq、微信、微信小程序等业务。拥有独立的小程序平台。\n- 华为云：有自产鲲鹏服务器，使用与绝大多数服务器不一样的arm架构（大部分服务器包括个人电脑都是amd64，也叫x86-64，但苹果的自研芯片M1是arm）。\n- 七牛云：阿里云出走大佬创办，有一定实力。\n- 青云：一个k8s开源集群管理系统的国内主导者。","slug":"123","published":1,"date":"2021-11-13T14:10:05.903Z","updated":"2021-11-13T15:03:09.358Z","title":"","comments":1,"layout":"post","photos":[],"link":"","_id":"ckvxyic6d0000e0ul5aptbnwi","content":"<h1 id=\"一个软件的诞生\"><a href=\"#一个软件的诞生\" class=\"headerlink\" title=\"一个软件的诞生\"></a>一个软件的诞生</h1><h2 id=\"开发过程\"><a href=\"#开发过程\" class=\"headerlink\" title=\"开发过程\"></a>开发过程</h2><p>准备：市场调查、需求分析……</p>\n<p>确定方案：技术，平台</p>\n<p>开发：</p>\n<ul>\n<li>设计&amp;前端：界面</li>\n<li>后端：业务逻辑</li>\n</ul>\n<p>上线：</p>\n<ul>\n<li>运营：宣传</li>\n<li>运维：服务器维护</li>\n</ul>\n<h1 id=\"传统的运维方式\"><a href=\"#传统的运维方式\" class=\"headerlink\" title=\"传统的运维方式\"></a>传统的运维方式</h1><p>把写好的软件部署到服务器上，跑就完事了。</p>\n<h2 id=\"如果业务量大了呢？\"><a href=\"#如果业务量大了呢？\" class=\"headerlink\" title=\"如果业务量大了呢？\"></a>如果业务量大了呢？</h2><p>用一样的方式部署到很多服务器上，跑就完事了。</p>\n<h2 id=\"有什么问题？\"><a href=\"#有什么问题？\" class=\"headerlink\" title=\"有什么问题？\"></a>有什么问题？</h2><ul>\n<li><strong>必须时刻以最大业务量安排服务器数量</strong>，成本高。</li>\n<li>每个公司都要有专职运维人员，招人难</li>\n<li>运维人员无论水平高低，所能管理的服务器数量有上限</li>\n<li>遇到突发状况，所需运维人员数量陡增，而保持一个大量运维团队需要高成本</li>\n</ul>\n<h1 id=\"一种趋势\"><a href=\"#一种趋势\" class=\"headerlink\" title=\"一种趋势\"></a>一种趋势</h1><p>所需管理的服务器数量庞大，但大部分工作都是重复的。所以……</p>\n<h2 id=\"CI-CD\"><a href=\"#CI-CD\" class=\"headerlink\" title=\"CI/CD\"></a>CI/CD</h2><p>持续集成，持续交付，持续部署。让后端开发人员（数量庞大，不乏牛人）来完成运维工作</p>\n<h2 id=\"Devops\"><a href=\"#Devops\" class=\"headerlink\" title=\"Devops\"></a>Devops</h2><p>运维开发，专门开发运维工具的人。试图将运维工作尽可能的自动化。</p>\n<h1 id=\"另一种趋势\"><a href=\"#另一种趋势\" class=\"headerlink\" title=\"另一种趋势\"></a>另一种趋势</h1><h2 id=\"虚拟化技术的进步\"><a href=\"#虚拟化技术的进步\" class=\"headerlink\" title=\"虚拟化技术的进步\"></a>虚拟化技术的进步</h2><p>最初的虚拟化：让windows的应用在mac上跑起来（纯举例），虚拟化的环境具有完整的系统，可以在另一个操作系统上跑起来。在性能上具有极大的开销（就是会很慢）</p>\n<p>容器化：让一个应用在一个容器中运行，该容器具有该应用所需的全部环境。一个容器就是一个进程，开销较小，与操作系统兼容良好（主要指linux）</p>\n<h2 id=\"容器时代\"><a href=\"#容器时代\" class=\"headerlink\" title=\"容器时代\"></a>容器时代</h2><p>不再关注各式各样的环境问题，所需要的环境都可以打包成容器，并且可以使用别人打包好的容器。</p>\n<p><strong>docker</strong>:第一个开源容器技术的公司，现在仍然是王者。</p>\n<p>docker的开源使得任何人都可以轻松部署各式各样的服务，因为环境的配置已经不是难题。但是对于企业来说，问题仍然存在：每个服务器上都可以跑好几个容器，就像以前一个服务器上可以跑好几个应用一样。如果有几千台呢？几万台呢？</p>\n<h2 id=\"容器编排\"><a href=\"#容器编排\" class=\"headerlink\" title=\"容器编排\"></a>容器编排</h2><p>能不能让不同的服务器上的容器连成一个整体？kubernetes给出了答案。</p>\n<p><strong>kubernetes</strong>:来自google，简称k8s，容器编排唯一的标准，生态的中心。</p>\n<p>允许将多个提供同一服务的容器打包成一个pod（豆荚），将多个服务器设置为一个cluster（集群），由k8s来决定pod在哪台服务器上运行。并且k8s可以在不同服务器上启动相同的pod，当一台服务器出现故障时，k8s迅速在其他服务器上添加故障服务器上运行的pod，从而保证了服务的稳定性。</p>\n<p>即成事实：<strong>k8s是生态的中心</strong></p>\n<p>围绕k8s的生态：监控，流水线部署，自动预警，网格化网关，容器化数据库以及<strong>serverless</strong></p>\n<p><em>k8s标志着云时代的正式开始</em></p>\n<h2 id=\"再进一步\"><a href=\"#再进一步\" class=\"headerlink\" title=\"再进一步\"></a>再进一步</h2><p>如果容器可以方便的创建和销毁，能不能更进一步？</p>\n<p>当有请求时才创建容器进行服务（而不是一直等着），请求结束就销毁容器，这便是<strong>Serverless</strong>，来自Amazon（亚马逊）</p>\n<p><strong>Serverless</strong>，无服务器技术，只有有需求的时候才服务。</p>\n<p>试想一个秒杀系统，在短暂的几秒内，服务器收到了数以亿记的请求，服务器立刻反应，创建大量容器进行服务，每服务完就立即销毁，把资源留给下一个创建的容器。而在几秒前或几秒后，服务器也许还处于一个“清闲”的状态。当前的serverless按照请求数计费，小公司无需按最大并发量购置服务器，只需直接购买serverless服务。</p>\n<h1 id=\"云服务现状\"><a href=\"#云服务现状\" class=\"headerlink\" title=\"云服务现状\"></a>云服务现状</h1><p>自k8s被推出以后，大公司们成立了CNCF（云原生计算基金会）。示例成员：google、AWS（亚马逊，世界最大的云服务供应商，serverless的领头羊）、RedHat（红帽，世界上最大的服务器软件公司，负责的centos操作系统跑在世界上百分之五十以上，中国百分之八十以上的服务器上）、docker、apache基金会（最成熟的服务器软件apache拥有者）、github、gitlab（二者分别为最大的代码托管网站和最大的开源私有git服务提供商）、华为（独立的鲲鹏架构）。</p>\n<h2 id=\"国内环境\"><a href=\"#国内环境\" class=\"headerlink\" title=\"国内环境\"></a>国内环境</h2><ul>\n<li>阿里云：全国最大的云服务供应商，对内为淘宝等提供服务，对外为各类企业提供云服务。</li>\n<li>腾讯云：对内有qq、微信、微信小程序等业务。拥有独立的小程序平台。</li>\n<li>华为云：有自产鲲鹏服务器，使用与绝大多数服务器不一样的arm架构（大部分服务器包括个人电脑都是amd64，也叫x86-64，但苹果的自研芯片M1是arm）。</li>\n<li>七牛云：阿里云出走大佬创办，有一定实力。</li>\n<li>青云：一个k8s开源集群管理系统的国内主导者。</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"一个软件的诞生\"><a href=\"#一个软件的诞生\" class=\"headerlink\" title=\"一个软件的诞生\"></a>一个软件的诞生</h1><h2 id=\"开发过程\"><a href=\"#开发过程\" class=\"headerlink\" title=\"开发过程\"></a>开发过程</h2><p>准备：市场调查、需求分析……</p>\n<p>确定方案：技术，平台</p>\n<p>开发：</p>\n<ul>\n<li>设计&amp;前端：界面</li>\n<li>后端：业务逻辑</li>\n</ul>\n<p>上线：</p>\n<ul>\n<li>运营：宣传</li>\n<li>运维：服务器维护</li>\n</ul>\n<h1 id=\"传统的运维方式\"><a href=\"#传统的运维方式\" class=\"headerlink\" title=\"传统的运维方式\"></a>传统的运维方式</h1><p>把写好的软件部署到服务器上，跑就完事了。</p>\n<h2 id=\"如果业务量大了呢？\"><a href=\"#如果业务量大了呢？\" class=\"headerlink\" title=\"如果业务量大了呢？\"></a>如果业务量大了呢？</h2><p>用一样的方式部署到很多服务器上，跑就完事了。</p>\n<h2 id=\"有什么问题？\"><a href=\"#有什么问题？\" class=\"headerlink\" title=\"有什么问题？\"></a>有什么问题？</h2><ul>\n<li><strong>必须时刻以最大业务量安排服务器数量</strong>，成本高。</li>\n<li>每个公司都要有专职运维人员，招人难</li>\n<li>运维人员无论水平高低，所能管理的服务器数量有上限</li>\n<li>遇到突发状况，所需运维人员数量陡增，而保持一个大量运维团队需要高成本</li>\n</ul>\n<h1 id=\"一种趋势\"><a href=\"#一种趋势\" class=\"headerlink\" title=\"一种趋势\"></a>一种趋势</h1><p>所需管理的服务器数量庞大，但大部分工作都是重复的。所以……</p>\n<h2 id=\"CI-CD\"><a href=\"#CI-CD\" class=\"headerlink\" title=\"CI/CD\"></a>CI/CD</h2><p>持续集成，持续交付，持续部署。让后端开发人员（数量庞大，不乏牛人）来完成运维工作</p>\n<h2 id=\"Devops\"><a href=\"#Devops\" class=\"headerlink\" title=\"Devops\"></a>Devops</h2><p>运维开发，专门开发运维工具的人。试图将运维工作尽可能的自动化。</p>\n<h1 id=\"另一种趋势\"><a href=\"#另一种趋势\" class=\"headerlink\" title=\"另一种趋势\"></a>另一种趋势</h1><h2 id=\"虚拟化技术的进步\"><a href=\"#虚拟化技术的进步\" class=\"headerlink\" title=\"虚拟化技术的进步\"></a>虚拟化技术的进步</h2><p>最初的虚拟化：让windows的应用在mac上跑起来（纯举例），虚拟化的环境具有完整的系统，可以在另一个操作系统上跑起来。在性能上具有极大的开销（就是会很慢）</p>\n<p>容器化：让一个应用在一个容器中运行，该容器具有该应用所需的全部环境。一个容器就是一个进程，开销较小，与操作系统兼容良好（主要指linux）</p>\n<h2 id=\"容器时代\"><a href=\"#容器时代\" class=\"headerlink\" title=\"容器时代\"></a>容器时代</h2><p>不再关注各式各样的环境问题，所需要的环境都可以打包成容器，并且可以使用别人打包好的容器。</p>\n<p><strong>docker</strong>:第一个开源容器技术的公司，现在仍然是王者。</p>\n<p>docker的开源使得任何人都可以轻松部署各式各样的服务，因为环境的配置已经不是难题。但是对于企业来说，问题仍然存在：每个服务器上都可以跑好几个容器，就像以前一个服务器上可以跑好几个应用一样。如果有几千台呢？几万台呢？</p>\n<h2 id=\"容器编排\"><a href=\"#容器编排\" class=\"headerlink\" title=\"容器编排\"></a>容器编排</h2><p>能不能让不同的服务器上的容器连成一个整体？kubernetes给出了答案。</p>\n<p><strong>kubernetes</strong>:来自google，简称k8s，容器编排唯一的标准，生态的中心。</p>\n<p>允许将多个提供同一服务的容器打包成一个pod（豆荚），将多个服务器设置为一个cluster（集群），由k8s来决定pod在哪台服务器上运行。并且k8s可以在不同服务器上启动相同的pod，当一台服务器出现故障时，k8s迅速在其他服务器上添加故障服务器上运行的pod，从而保证了服务的稳定性。</p>\n<p>即成事实：<strong>k8s是生态的中心</strong></p>\n<p>围绕k8s的生态：监控，流水线部署，自动预警，网格化网关，容器化数据库以及<strong>serverless</strong></p>\n<p><em>k8s标志着云时代的正式开始</em></p>\n<h2 id=\"再进一步\"><a href=\"#再进一步\" class=\"headerlink\" title=\"再进一步\"></a>再进一步</h2><p>如果容器可以方便的创建和销毁，能不能更进一步？</p>\n<p>当有请求时才创建容器进行服务（而不是一直等着），请求结束就销毁容器，这便是<strong>Serverless</strong>，来自Amazon（亚马逊）</p>\n<p><strong>Serverless</strong>，无服务器技术，只有有需求的时候才服务。</p>\n<p>试想一个秒杀系统，在短暂的几秒内，服务器收到了数以亿记的请求，服务器立刻反应，创建大量容器进行服务，每服务完就立即销毁，把资源留给下一个创建的容器。而在几秒前或几秒后，服务器也许还处于一个“清闲”的状态。当前的serverless按照请求数计费，小公司无需按最大并发量购置服务器，只需直接购买serverless服务。</p>\n<h1 id=\"云服务现状\"><a href=\"#云服务现状\" class=\"headerlink\" title=\"云服务现状\"></a>云服务现状</h1><p>自k8s被推出以后，大公司们成立了CNCF（云原生计算基金会）。示例成员：google、AWS（亚马逊，世界最大的云服务供应商，serverless的领头羊）、RedHat（红帽，世界上最大的服务器软件公司，负责的centos操作系统跑在世界上百分之五十以上，中国百分之八十以上的服务器上）、docker、apache基金会（最成熟的服务器软件apache拥有者）、github、gitlab（二者分别为最大的代码托管网站和最大的开源私有git服务提供商）、华为（独立的鲲鹏架构）。</p>\n<h2 id=\"国内环境\"><a href=\"#国内环境\" class=\"headerlink\" title=\"国内环境\"></a>国内环境</h2><ul>\n<li>阿里云：全国最大的云服务供应商，对内为淘宝等提供服务，对外为各类企业提供云服务。</li>\n<li>腾讯云：对内有qq、微信、微信小程序等业务。拥有独立的小程序平台。</li>\n<li>华为云：有自产鲲鹏服务器，使用与绝大多数服务器不一样的arm架构（大部分服务器包括个人电脑都是amd64，也叫x86-64，但苹果的自研芯片M1是arm）。</li>\n<li>七牛云：阿里云出走大佬创办，有一定实力。</li>\n<li>青云：一个k8s开源集群管理系统的国内主导者。</li>\n</ul>\n"},{"author":"kawhicurry","title":"net-server-0","date":"2021-11-13T15:20:43.000Z","_content":"\n# 一个软件的诞生\n\n## 开发过程\n\n准备：市场调查、需求分析……\n\n确定方案：技术，平台\n\n开发：\n\n- 设计&前端：界面\n- 后端：业务逻辑\n\n上线：\n\n- 运营：宣传\n- 运维：服务器维护\n\n# 传统的运维方式\n\n把写好的软件部署到服务器上，跑就完事了。\n\n## 如果业务量大了呢？\n\n用一样的方式部署到很多服务器上，跑就完事了。\n\n## 有什么问题？\n\n- **必须时刻以最大业务量安排服务器数量**，成本高。\n- 每个公司都要有专职运维人员，招人难\n- 运维人员无论水平高低，所能管理的服务器数量有上限\n- 遇到突发状况，所需运维人员数量陡增，而保持一个大量运维团队需要高成本\n\n# 一种趋势\n\n所需管理的服务器数量庞大，但大部分工作都是重复的。所以……\n\n## CI/CD\n\n持续集成，持续交付，持续部署。让后端开发人员（数量庞大，不乏牛人）来完成运维工作\n\n## Devops\n\n运维开发，专门开发运维工具的人。试图将运维工作尽可能的自动化。\n\n# 另一种趋势\n\n## 虚拟化技术的进步\n\n最初的虚拟化：让windows的应用在mac上跑起来（纯举例），虚拟化的环境具有完整的系统，可以在另一个操作系统上跑起来。在性能上具有极大的开销（就是会很慢）\n\n容器化：让一个应用在一个容器中运行，该容器具有该应用所需的全部环境。一个容器就是一个进程，开销较小，与操作系统兼容良好（主要指linux）\n\n## 容器时代\n\n不再关注各式各样的环境问题，所需要的环境都可以打包成容器，并且可以使用别人打包好的容器。\n\n**docker**:第一个开源容器技术的公司，现在仍然是王者。\n\ndocker的开源使得任何人都可以轻松部署各式各样的服务，因为环境的配置已经不是难题。但是对于企业来说，问题仍然存在：每个服务器上都可以跑好几个容器，就像以前一个服务器上可以跑好几个应用一样。如果有几千台呢？几万台呢？\n\n## 容器编排\n\n能不能让不同的服务器上的容器连成一个整体？kubernetes给出了答案。\n\n**kubernetes**:来自google，简称k8s，容器编排唯一的标准，生态的中心。\n\n允许将多个提供同一服务的容器打包成一个pod（豆荚），将多个服务器设置为一个cluster（集群），由k8s来决定pod在哪台服务器上运行。并且k8s可以在不同服务器上启动相同的pod，当一台服务器出现故障时，k8s迅速在其他服务器上添加故障服务器上运行的pod，从而保证了服务的稳定性。\n\n即成事实：**k8s是生态的中心**\n\n围绕k8s的生态：监控，流水线部署，自动预警，网格化网关，容器化数据库以及**serverless**\n\n*k8s标志着云时代的正式开始*\n\n## 再进一步\n\n如果容器可以方便的创建和销毁，能不能更进一步？\n\n当有请求时才创建容器进行服务（而不是一直等着），请求结束就销毁容器，这便是**Serverless**，来自Amazon（亚马逊）\n\n**Serverless**，无服务器技术，只有有需求的时候才服务。\n\n试想一个秒杀系统，在短暂的几秒内，服务器收到了数以亿记的请求，服务器立刻反应，创建大量容器进行服务，每服务完就立即销毁，把资源留给下一个创建的容器。而在几秒前或几秒后，服务器也许还处于一个“清闲”的状态。当前的serverless按照请求数计费，小公司无需按最大并发量购置服务器，只需直接购买serverless服务。\n\n# 云服务现状\n\n自k8s被推出以后，大公司们成立了CNCF（云原生计算基金会）。示例成员：google、AWS（亚马逊，世界最大的云服务供应商，serverless的领头羊）、RedHat（红帽，世界上最大的服务器软件公司，负责的centos操作系统跑在世界上百分之五十以上，中国百分之八十以上的服务器上）、docker、apache基金会（最成熟的服务器软件apache拥有者）、github、gitlab（二者分别为最大的代码托管网站和最大的开源私有git服务提供商）、华为（独立的鲲鹏架构）。\n\n## 国内环境\n\n- 阿里云：全国最大的云服务供应商，对内为淘宝等提供服务，对外为各类企业提供云服务。\n- 腾讯云：对内有qq、微信、微信小程序等业务。拥有独立的小程序平台。\n- 华为云：有自产鲲鹏服务器，使用与绝大多数服务器不一样的arm架构（大部分服务器包括个人电脑都是amd64，也叫x86-64，但苹果的自研芯片M1是arm）。\n- 七牛云：阿里云出走大佬创办，有一定实力。\n- 青云：一个k8s开源集群管理系统的国内主导者。","source":"_posts/net-server-0.md","raw":"---\nauthor: kawhicurry\ntitle: net-server-0\ncategories: uncategorized\ndate: 2021-11-13 23:20:43\ntags: cloud\n---\n\n# 一个软件的诞生\n\n## 开发过程\n\n准备：市场调查、需求分析……\n\n确定方案：技术，平台\n\n开发：\n\n- 设计&前端：界面\n- 后端：业务逻辑\n\n上线：\n\n- 运营：宣传\n- 运维：服务器维护\n\n# 传统的运维方式\n\n把写好的软件部署到服务器上，跑就完事了。\n\n## 如果业务量大了呢？\n\n用一样的方式部署到很多服务器上，跑就完事了。\n\n## 有什么问题？\n\n- **必须时刻以最大业务量安排服务器数量**，成本高。\n- 每个公司都要有专职运维人员，招人难\n- 运维人员无论水平高低，所能管理的服务器数量有上限\n- 遇到突发状况，所需运维人员数量陡增，而保持一个大量运维团队需要高成本\n\n# 一种趋势\n\n所需管理的服务器数量庞大，但大部分工作都是重复的。所以……\n\n## CI/CD\n\n持续集成，持续交付，持续部署。让后端开发人员（数量庞大，不乏牛人）来完成运维工作\n\n## Devops\n\n运维开发，专门开发运维工具的人。试图将运维工作尽可能的自动化。\n\n# 另一种趋势\n\n## 虚拟化技术的进步\n\n最初的虚拟化：让windows的应用在mac上跑起来（纯举例），虚拟化的环境具有完整的系统，可以在另一个操作系统上跑起来。在性能上具有极大的开销（就是会很慢）\n\n容器化：让一个应用在一个容器中运行，该容器具有该应用所需的全部环境。一个容器就是一个进程，开销较小，与操作系统兼容良好（主要指linux）\n\n## 容器时代\n\n不再关注各式各样的环境问题，所需要的环境都可以打包成容器，并且可以使用别人打包好的容器。\n\n**docker**:第一个开源容器技术的公司，现在仍然是王者。\n\ndocker的开源使得任何人都可以轻松部署各式各样的服务，因为环境的配置已经不是难题。但是对于企业来说，问题仍然存在：每个服务器上都可以跑好几个容器，就像以前一个服务器上可以跑好几个应用一样。如果有几千台呢？几万台呢？\n\n## 容器编排\n\n能不能让不同的服务器上的容器连成一个整体？kubernetes给出了答案。\n\n**kubernetes**:来自google，简称k8s，容器编排唯一的标准，生态的中心。\n\n允许将多个提供同一服务的容器打包成一个pod（豆荚），将多个服务器设置为一个cluster（集群），由k8s来决定pod在哪台服务器上运行。并且k8s可以在不同服务器上启动相同的pod，当一台服务器出现故障时，k8s迅速在其他服务器上添加故障服务器上运行的pod，从而保证了服务的稳定性。\n\n即成事实：**k8s是生态的中心**\n\n围绕k8s的生态：监控，流水线部署，自动预警，网格化网关，容器化数据库以及**serverless**\n\n*k8s标志着云时代的正式开始*\n\n## 再进一步\n\n如果容器可以方便的创建和销毁，能不能更进一步？\n\n当有请求时才创建容器进行服务（而不是一直等着），请求结束就销毁容器，这便是**Serverless**，来自Amazon（亚马逊）\n\n**Serverless**，无服务器技术，只有有需求的时候才服务。\n\n试想一个秒杀系统，在短暂的几秒内，服务器收到了数以亿记的请求，服务器立刻反应，创建大量容器进行服务，每服务完就立即销毁，把资源留给下一个创建的容器。而在几秒前或几秒后，服务器也许还处于一个“清闲”的状态。当前的serverless按照请求数计费，小公司无需按最大并发量购置服务器，只需直接购买serverless服务。\n\n# 云服务现状\n\n自k8s被推出以后，大公司们成立了CNCF（云原生计算基金会）。示例成员：google、AWS（亚马逊，世界最大的云服务供应商，serverless的领头羊）、RedHat（红帽，世界上最大的服务器软件公司，负责的centos操作系统跑在世界上百分之五十以上，中国百分之八十以上的服务器上）、docker、apache基金会（最成熟的服务器软件apache拥有者）、github、gitlab（二者分别为最大的代码托管网站和最大的开源私有git服务提供商）、华为（独立的鲲鹏架构）。\n\n## 国内环境\n\n- 阿里云：全国最大的云服务供应商，对内为淘宝等提供服务，对外为各类企业提供云服务。\n- 腾讯云：对内有qq、微信、微信小程序等业务。拥有独立的小程序平台。\n- 华为云：有自产鲲鹏服务器，使用与绝大多数服务器不一样的arm架构（大部分服务器包括个人电脑都是amd64，也叫x86-64，但苹果的自研芯片M1是arm）。\n- 七牛云：阿里云出走大佬创办，有一定实力。\n- 青云：一个k8s开源集群管理系统的国内主导者。","slug":"net-server-0","published":1,"updated":"2021-11-13T15:21:15.570Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckvxyic780001e0ul55zv0y4y","content":"<h1 id=\"一个软件的诞生\"><a href=\"#一个软件的诞生\" class=\"headerlink\" title=\"一个软件的诞生\"></a>一个软件的诞生</h1><h2 id=\"开发过程\"><a href=\"#开发过程\" class=\"headerlink\" title=\"开发过程\"></a>开发过程</h2><p>准备：市场调查、需求分析……</p>\n<p>确定方案：技术，平台</p>\n<p>开发：</p>\n<ul>\n<li>设计&amp;前端：界面</li>\n<li>后端：业务逻辑</li>\n</ul>\n<p>上线：</p>\n<ul>\n<li>运营：宣传</li>\n<li>运维：服务器维护</li>\n</ul>\n<h1 id=\"传统的运维方式\"><a href=\"#传统的运维方式\" class=\"headerlink\" title=\"传统的运维方式\"></a>传统的运维方式</h1><p>把写好的软件部署到服务器上，跑就完事了。</p>\n<h2 id=\"如果业务量大了呢？\"><a href=\"#如果业务量大了呢？\" class=\"headerlink\" title=\"如果业务量大了呢？\"></a>如果业务量大了呢？</h2><p>用一样的方式部署到很多服务器上，跑就完事了。</p>\n<h2 id=\"有什么问题？\"><a href=\"#有什么问题？\" class=\"headerlink\" title=\"有什么问题？\"></a>有什么问题？</h2><ul>\n<li><strong>必须时刻以最大业务量安排服务器数量</strong>，成本高。</li>\n<li>每个公司都要有专职运维人员，招人难</li>\n<li>运维人员无论水平高低，所能管理的服务器数量有上限</li>\n<li>遇到突发状况，所需运维人员数量陡增，而保持一个大量运维团队需要高成本</li>\n</ul>\n<h1 id=\"一种趋势\"><a href=\"#一种趋势\" class=\"headerlink\" title=\"一种趋势\"></a>一种趋势</h1><p>所需管理的服务器数量庞大，但大部分工作都是重复的。所以……</p>\n<h2 id=\"CI-CD\"><a href=\"#CI-CD\" class=\"headerlink\" title=\"CI/CD\"></a>CI/CD</h2><p>持续集成，持续交付，持续部署。让后端开发人员（数量庞大，不乏牛人）来完成运维工作</p>\n<h2 id=\"Devops\"><a href=\"#Devops\" class=\"headerlink\" title=\"Devops\"></a>Devops</h2><p>运维开发，专门开发运维工具的人。试图将运维工作尽可能的自动化。</p>\n<h1 id=\"另一种趋势\"><a href=\"#另一种趋势\" class=\"headerlink\" title=\"另一种趋势\"></a>另一种趋势</h1><h2 id=\"虚拟化技术的进步\"><a href=\"#虚拟化技术的进步\" class=\"headerlink\" title=\"虚拟化技术的进步\"></a>虚拟化技术的进步</h2><p>最初的虚拟化：让windows的应用在mac上跑起来（纯举例），虚拟化的环境具有完整的系统，可以在另一个操作系统上跑起来。在性能上具有极大的开销（就是会很慢）</p>\n<p>容器化：让一个应用在一个容器中运行，该容器具有该应用所需的全部环境。一个容器就是一个进程，开销较小，与操作系统兼容良好（主要指linux）</p>\n<h2 id=\"容器时代\"><a href=\"#容器时代\" class=\"headerlink\" title=\"容器时代\"></a>容器时代</h2><p>不再关注各式各样的环境问题，所需要的环境都可以打包成容器，并且可以使用别人打包好的容器。</p>\n<p><strong>docker</strong>:第一个开源容器技术的公司，现在仍然是王者。</p>\n<p>docker的开源使得任何人都可以轻松部署各式各样的服务，因为环境的配置已经不是难题。但是对于企业来说，问题仍然存在：每个服务器上都可以跑好几个容器，就像以前一个服务器上可以跑好几个应用一样。如果有几千台呢？几万台呢？</p>\n<h2 id=\"容器编排\"><a href=\"#容器编排\" class=\"headerlink\" title=\"容器编排\"></a>容器编排</h2><p>能不能让不同的服务器上的容器连成一个整体？kubernetes给出了答案。</p>\n<p><strong>kubernetes</strong>:来自google，简称k8s，容器编排唯一的标准，生态的中心。</p>\n<p>允许将多个提供同一服务的容器打包成一个pod（豆荚），将多个服务器设置为一个cluster（集群），由k8s来决定pod在哪台服务器上运行。并且k8s可以在不同服务器上启动相同的pod，当一台服务器出现故障时，k8s迅速在其他服务器上添加故障服务器上运行的pod，从而保证了服务的稳定性。</p>\n<p>即成事实：<strong>k8s是生态的中心</strong></p>\n<p>围绕k8s的生态：监控，流水线部署，自动预警，网格化网关，容器化数据库以及<strong>serverless</strong></p>\n<p><em>k8s标志着云时代的正式开始</em></p>\n<h2 id=\"再进一步\"><a href=\"#再进一步\" class=\"headerlink\" title=\"再进一步\"></a>再进一步</h2><p>如果容器可以方便的创建和销毁，能不能更进一步？</p>\n<p>当有请求时才创建容器进行服务（而不是一直等着），请求结束就销毁容器，这便是<strong>Serverless</strong>，来自Amazon（亚马逊）</p>\n<p><strong>Serverless</strong>，无服务器技术，只有有需求的时候才服务。</p>\n<p>试想一个秒杀系统，在短暂的几秒内，服务器收到了数以亿记的请求，服务器立刻反应，创建大量容器进行服务，每服务完就立即销毁，把资源留给下一个创建的容器。而在几秒前或几秒后，服务器也许还处于一个“清闲”的状态。当前的serverless按照请求数计费，小公司无需按最大并发量购置服务器，只需直接购买serverless服务。</p>\n<h1 id=\"云服务现状\"><a href=\"#云服务现状\" class=\"headerlink\" title=\"云服务现状\"></a>云服务现状</h1><p>自k8s被推出以后，大公司们成立了CNCF（云原生计算基金会）。示例成员：google、AWS（亚马逊，世界最大的云服务供应商，serverless的领头羊）、RedHat（红帽，世界上最大的服务器软件公司，负责的centos操作系统跑在世界上百分之五十以上，中国百分之八十以上的服务器上）、docker、apache基金会（最成熟的服务器软件apache拥有者）、github、gitlab（二者分别为最大的代码托管网站和最大的开源私有git服务提供商）、华为（独立的鲲鹏架构）。</p>\n<h2 id=\"国内环境\"><a href=\"#国内环境\" class=\"headerlink\" title=\"国内环境\"></a>国内环境</h2><ul>\n<li>阿里云：全国最大的云服务供应商，对内为淘宝等提供服务，对外为各类企业提供云服务。</li>\n<li>腾讯云：对内有qq、微信、微信小程序等业务。拥有独立的小程序平台。</li>\n<li>华为云：有自产鲲鹏服务器，使用与绝大多数服务器不一样的arm架构（大部分服务器包括个人电脑都是amd64，也叫x86-64，但苹果的自研芯片M1是arm）。</li>\n<li>七牛云：阿里云出走大佬创办，有一定实力。</li>\n<li>青云：一个k8s开源集群管理系统的国内主导者。</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"一个软件的诞生\"><a href=\"#一个软件的诞生\" class=\"headerlink\" title=\"一个软件的诞生\"></a>一个软件的诞生</h1><h2 id=\"开发过程\"><a href=\"#开发过程\" class=\"headerlink\" title=\"开发过程\"></a>开发过程</h2><p>准备：市场调查、需求分析……</p>\n<p>确定方案：技术，平台</p>\n<p>开发：</p>\n<ul>\n<li>设计&amp;前端：界面</li>\n<li>后端：业务逻辑</li>\n</ul>\n<p>上线：</p>\n<ul>\n<li>运营：宣传</li>\n<li>运维：服务器维护</li>\n</ul>\n<h1 id=\"传统的运维方式\"><a href=\"#传统的运维方式\" class=\"headerlink\" title=\"传统的运维方式\"></a>传统的运维方式</h1><p>把写好的软件部署到服务器上，跑就完事了。</p>\n<h2 id=\"如果业务量大了呢？\"><a href=\"#如果业务量大了呢？\" class=\"headerlink\" title=\"如果业务量大了呢？\"></a>如果业务量大了呢？</h2><p>用一样的方式部署到很多服务器上，跑就完事了。</p>\n<h2 id=\"有什么问题？\"><a href=\"#有什么问题？\" class=\"headerlink\" title=\"有什么问题？\"></a>有什么问题？</h2><ul>\n<li><strong>必须时刻以最大业务量安排服务器数量</strong>，成本高。</li>\n<li>每个公司都要有专职运维人员，招人难</li>\n<li>运维人员无论水平高低，所能管理的服务器数量有上限</li>\n<li>遇到突发状况，所需运维人员数量陡增，而保持一个大量运维团队需要高成本</li>\n</ul>\n<h1 id=\"一种趋势\"><a href=\"#一种趋势\" class=\"headerlink\" title=\"一种趋势\"></a>一种趋势</h1><p>所需管理的服务器数量庞大，但大部分工作都是重复的。所以……</p>\n<h2 id=\"CI-CD\"><a href=\"#CI-CD\" class=\"headerlink\" title=\"CI/CD\"></a>CI/CD</h2><p>持续集成，持续交付，持续部署。让后端开发人员（数量庞大，不乏牛人）来完成运维工作</p>\n<h2 id=\"Devops\"><a href=\"#Devops\" class=\"headerlink\" title=\"Devops\"></a>Devops</h2><p>运维开发，专门开发运维工具的人。试图将运维工作尽可能的自动化。</p>\n<h1 id=\"另一种趋势\"><a href=\"#另一种趋势\" class=\"headerlink\" title=\"另一种趋势\"></a>另一种趋势</h1><h2 id=\"虚拟化技术的进步\"><a href=\"#虚拟化技术的进步\" class=\"headerlink\" title=\"虚拟化技术的进步\"></a>虚拟化技术的进步</h2><p>最初的虚拟化：让windows的应用在mac上跑起来（纯举例），虚拟化的环境具有完整的系统，可以在另一个操作系统上跑起来。在性能上具有极大的开销（就是会很慢）</p>\n<p>容器化：让一个应用在一个容器中运行，该容器具有该应用所需的全部环境。一个容器就是一个进程，开销较小，与操作系统兼容良好（主要指linux）</p>\n<h2 id=\"容器时代\"><a href=\"#容器时代\" class=\"headerlink\" title=\"容器时代\"></a>容器时代</h2><p>不再关注各式各样的环境问题，所需要的环境都可以打包成容器，并且可以使用别人打包好的容器。</p>\n<p><strong>docker</strong>:第一个开源容器技术的公司，现在仍然是王者。</p>\n<p>docker的开源使得任何人都可以轻松部署各式各样的服务，因为环境的配置已经不是难题。但是对于企业来说，问题仍然存在：每个服务器上都可以跑好几个容器，就像以前一个服务器上可以跑好几个应用一样。如果有几千台呢？几万台呢？</p>\n<h2 id=\"容器编排\"><a href=\"#容器编排\" class=\"headerlink\" title=\"容器编排\"></a>容器编排</h2><p>能不能让不同的服务器上的容器连成一个整体？kubernetes给出了答案。</p>\n<p><strong>kubernetes</strong>:来自google，简称k8s，容器编排唯一的标准，生态的中心。</p>\n<p>允许将多个提供同一服务的容器打包成一个pod（豆荚），将多个服务器设置为一个cluster（集群），由k8s来决定pod在哪台服务器上运行。并且k8s可以在不同服务器上启动相同的pod，当一台服务器出现故障时，k8s迅速在其他服务器上添加故障服务器上运行的pod，从而保证了服务的稳定性。</p>\n<p>即成事实：<strong>k8s是生态的中心</strong></p>\n<p>围绕k8s的生态：监控，流水线部署，自动预警，网格化网关，容器化数据库以及<strong>serverless</strong></p>\n<p><em>k8s标志着云时代的正式开始</em></p>\n<h2 id=\"再进一步\"><a href=\"#再进一步\" class=\"headerlink\" title=\"再进一步\"></a>再进一步</h2><p>如果容器可以方便的创建和销毁，能不能更进一步？</p>\n<p>当有请求时才创建容器进行服务（而不是一直等着），请求结束就销毁容器，这便是<strong>Serverless</strong>，来自Amazon（亚马逊）</p>\n<p><strong>Serverless</strong>，无服务器技术，只有有需求的时候才服务。</p>\n<p>试想一个秒杀系统，在短暂的几秒内，服务器收到了数以亿记的请求，服务器立刻反应，创建大量容器进行服务，每服务完就立即销毁，把资源留给下一个创建的容器。而在几秒前或几秒后，服务器也许还处于一个“清闲”的状态。当前的serverless按照请求数计费，小公司无需按最大并发量购置服务器，只需直接购买serverless服务。</p>\n<h1 id=\"云服务现状\"><a href=\"#云服务现状\" class=\"headerlink\" title=\"云服务现状\"></a>云服务现状</h1><p>自k8s被推出以后，大公司们成立了CNCF（云原生计算基金会）。示例成员：google、AWS（亚马逊，世界最大的云服务供应商，serverless的领头羊）、RedHat（红帽，世界上最大的服务器软件公司，负责的centos操作系统跑在世界上百分之五十以上，中国百分之八十以上的服务器上）、docker、apache基金会（最成熟的服务器软件apache拥有者）、github、gitlab（二者分别为最大的代码托管网站和最大的开源私有git服务提供商）、华为（独立的鲲鹏架构）。</p>\n<h2 id=\"国内环境\"><a href=\"#国内环境\" class=\"headerlink\" title=\"国内环境\"></a>国内环境</h2><ul>\n<li>阿里云：全国最大的云服务供应商，对内为淘宝等提供服务，对外为各类企业提供云服务。</li>\n<li>腾讯云：对内有qq、微信、微信小程序等业务。拥有独立的小程序平台。</li>\n<li>华为云：有自产鲲鹏服务器，使用与绝大多数服务器不一样的arm架构（大部分服务器包括个人电脑都是amd64，也叫x86-64，但苹果的自研芯片M1是arm）。</li>\n<li>七牛云：阿里云出走大佬创办，有一定实力。</li>\n<li>青云：一个k8s开源集群管理系统的国内主导者。</li>\n</ul>\n"}],"PostAsset":[],"PostCategory":[{"post_id":"ckv9h3bhl0005e0ul6ox31j9y","category_id":"ckv9h3bhm0007e0ul1maa6qdr","_id":"ckv9h3bhn0008e0ul6304chk1"},{"post_id":"ckvp97s0y0000a4ul9ha3c995","category_id":"ckvp97s130001a4ulg84g3g0u","_id":"ckvp97s170004a4ule6rm1p69"},{"post_id":"ckvthffej0000bkul3r911bwx","category_id":"ckvthffer0001bkulfdvge9xx","_id":"ckvthffev0004bkulbp2xbptg"},{"post_id":"ckvxyic780001e0ul55zv0y4y","category_id":"ckvxyic7a0002e0ulf852d98u","_id":"ckvxyic7g0005e0ul02449lxq"}],"PostTag":[{"post_id":"ckv9h3bh40000e0ula1dfa3j2","tag_id":"ckv9h3bhf0002e0uldnucf393","_id":"ckv9h3bhm0006e0ulgz9fakho"},{"post_id":"ckvp97s0y0000a4ul9ha3c995","tag_id":"ckvp97s150002a4ul0zja98oj","_id":"ckvp97s160003a4ul2xuvhakb"},{"post_id":"ckvthffej0000bkul3r911bwx","tag_id":"ckvthffeu0002bkul4ujf39rr","_id":"ckvthffev0003bkul9236gv23"},{"post_id":"ckvxyic780001e0ul55zv0y4y","tag_id":"ckvxyic7e0003e0ulgecebgrq","_id":"ckvxyic7g0004e0ulfo7k0bin"}],"Tag":[{"name":"Daily","_id":"ckv9h3bhf0002e0uldnucf393"},{"name":"C","_id":"ckvp97s150002a4ul0zja98oj"},{"name":"git","_id":"ckvthffeu0002bkul4ujf39rr"},{"name":"cloud","_id":"ckvxyic7e0003e0ulgecebgrq"}]}}